{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# –õ–∞–±–∞ 2\n",
    "\n",
    "**–î–µ–¥–ª–∞–π–Ω**: 25 –Ω–æ—è–±—Ä—è\n",
    "\n",
    "**–ó–∞–¥–∞—á–∞**: –Ω–∞–ø–∏—Å–∞—Ç—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ (—Å–æ–æ–±—â–µ–Ω–∏–µ—è –≤ Twitter) c –ø–æ–º–æ—â—å—é fine-tuning-–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ RuSentiTweet (https://github.com/sismetanin/rusentitweet)\n",
    "\n",
    "–ù–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ:\n",
    "* (+)–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–æ—á–∏—Å—Ç–∫–∞, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ —É–ø–∞–∫–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ —É–¥–æ–±–Ω—ã–π –∫–ª–∞—Å—Å) - —É –≤–∞—Å –≤ –∑–∞–¥–∞–Ω–∏–∏ –¥—Ä—É–≥–æ–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–∂–µ—Ç –ø–æ–º–µ–Ω—è—Ç—å—Å—è. –í –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤, —Å–∫–∞—á–∞–π—Ç–µ rusentitweet_full.csv –∏ —Ä–∞–±–æ—Ç–∞–π—Ç–µ —Å –Ω–∏–º\n",
    "* (+)–ü—Ä–æ—Ü–µ–¥—É—Ä–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è. –í–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å –∏–º–µ—é—â—É—é—Å—è –ø—Ä–æ—Ü–µ–¥—É—Ä—É:\n",
    "    * (+-) –î–æ–±–∞–≤–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —à–∞–≥–∞ (–¥–µ–ª–∞—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –∫–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä), –∞ –Ω–µ —Ä–∞–∑ –≤ —ç–ø–æ—Ö—É)\n",
    "    * (+) –ó–∞–º–µ—Ä–∏—Ç—å –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è\n",
    "    * (-) –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è (–∏–∑—É—á–∏—Ç–µ –ø–æ –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º, –∫–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –∑–∞–¥–∞—á–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø–æ—á–µ–º—É)\n",
    "        * ![](./images/img_1.png)\n",
    "    * (+) –î–æ–±–∞–≤–∏—Ç—å –∑–∞–º–æ—Ä–æ–∑–∫—É —á–∞—Å—Ç–∏ —Å–ª–æ–µ–≤ (–≤—Å–µ, –∫—Ä–æ–º–µ —Å–ª–æ—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –∏–ª–∏ –∫—Ä–æ–º–µ —Å–ª–æ—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ + 2-3 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–ª–æ–µ–≤ —Å –∏–Ω—Ç–µ–Ω—Ç–∞–º–∏)\n",
    "    * (+-) –ü–æ–¥–æ–±—Ä–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö, —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –∏ –∑–∞–º–æ—Ä–æ–∑–∫—É —Ç–∞–∫, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –¥–∞–≤–∞–ª–∞ –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "* (+)–ú–æ–¥–µ–ª—å –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è (–ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∫–∞–∫ –º–∏–Ω–∏–º—É–º 2 —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–∏), –∏—Å–∫–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ —Å –ø–æ–º–æ—â—å—é –≥—É–≥–ª–∞ –∏ https://huggingface.co/\n",
    "* (+)–†–µ–∑—É–ª—å—Ç–∞—Ç—ã **–≤—Å–µ—Ö** —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–ø–∏—Å–∞–Ω—ã –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–µ\n",
    "* (+)Inference –º–æ–¥–µ–ª–∏ - –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –Ω—É–∂–Ω–æ –æ–±–µ—Ä–Ω—É—Ç—å –≤ —É–¥–æ–±–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø–æ —Ç–µ–∫—Å—Ç—É –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –µ–≥–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=xI0HHN5XKDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## –ò–º–ø–æ—Ä—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import typing, re, torch, os.path, sys, emot, torchmetrics, functools, gc\n",
    "\n",
    "from torch.utils.data.dataset import T_co\n",
    "\n",
    "# –∫–æ—Å—Ç—ã–ª—å, —á—Ç–æ–± –æ–±—â–∏–π —Ñ–∞–π–ª–∏–∫ —Å–≥—Ä—É–∑–∏—Ç—å\n",
    "if not sys.path.__contains__('..'):\n",
    "    sys.path.insert(0, '..')\n",
    "import helper\n",
    "\n",
    "from num2words import num2words\n",
    "from cleantext import clean\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "emot_core = emot.core.emot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "SPLIT_SIZE = 0.3\n",
    "NUM_WORKERS = 4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–†–∞–∑–±–µ—Ä–µ–º—Å—è —Å –¥–∞–Ω–Ω—ã–º–∏ - —É–±–µ—Ä–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏, —Å–∏–º–≤–æ–ª—ã –∏ —Ç.–¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–Ω–∞ –æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Å—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ö–∞–∫ –≤—Å–µ–≥–¥–∞ - –Ω–∞ –≤—Å–µ —Å–ª—É—á–∞–∏ –∂–∏–∑–Ω–∏ –µ—Å—Ç—å –±–∏–±–ª–∏–æ—Ç–µ—á–∫–∏.\n",
    "# –û–¥–Ω–∞–∫–æ –∑–∞—á–µ–º-—Ç–æ —è —Ä–µ—à–∏–ª –Ω–∞—Å—Ç–æ–ª—å–∫–æ –æ—á–∏—Å—Ç–∫–æ–π –∑–∞–º–æ—Ä–æ—á–∏—Ç—å—Å—è, —á—Ç–æ –¥–∞–∂–µ —ç–º–æ—Ç–∏–∫–æ–Ω—ã –≤—ã—Ç–∞—â–∏–ª, –∏ –≤–æ—Ç –Ω–∞ —ç—Ç–æ –±–∏–±–ª–∏–æ—Ç–µ–∫ –Ω–µ –±—ã–ª–æ\n",
    "\n",
    "def num2words_with_extract(text: typing.AnyStr) -> typing.AnyStr:\n",
    "    split_text = text.split(' ')\n",
    "    for idx, segment in enumerate(split_text):\n",
    "        if segment.isdigit():\n",
    "            split_text[idx] = num2words(segment, lang='ru')\n",
    "    return \" \".join(split_text)\n",
    "\n",
    "\n",
    "def remove_emoticons(text: typing.AnyStr, emot_core) -> typing.AnyStr:  # TODO: write your own emoticon regexp\n",
    "    res = emot_core.emoticons(text)\n",
    "    for emoticon in res['value']:\n",
    "        # print(emoticon)\n",
    "        regex = '(?:'\n",
    "        for symbol in [*emoticon]:\n",
    "            regex += (symbol if symbol.isalpha() or symbol.isdigit() else '\\\\' + symbol) + '+'\n",
    "        regex += ')'\n",
    "        # print(regex)\n",
    "        compiled = re.compile(regex)\n",
    "        text = compiled.sub(r'', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_text(text: typing.AnyStr, emot_core=emot_core) -> typing.AnyStr:\n",
    "    text = clean(\n",
    "        text=text,\n",
    "        fix_unicode=False,  # fix various unicode errors\n",
    "        to_ascii=False,  # transliterate to closest ASCII representation\n",
    "        lower=True,  # lowercase text\n",
    "        no_line_breaks=True,  # fully strip line breaks as opposed to only normalizing them\n",
    "        no_urls=True,  # replace all URLs with a special token\n",
    "        no_emails=True,  # replace all email addresses with a special token\n",
    "        no_phone_numbers=True,  # replace all phone numbers with a special token\n",
    "        no_emoji=True,\n",
    "        no_numbers=False,  # replace all numbers with a special token\n",
    "        no_digits=False,  # replace all digits with a special token\n",
    "        no_currency_symbols=False,  # replace all currency symbols with a special token\n",
    "        no_punct=False,  # remove punctuations\n",
    "        normalize_whitespace=True,\n",
    "        replace_with_punct=\"\",  # instead of removing punctuations you may replace them\n",
    "        replace_with_url=\"\",\n",
    "        replace_with_email=\"\",\n",
    "        replace_with_phone_number=\"\",\n",
    "        replace_with_number=\"\",\n",
    "        replace_with_digit=\"\",\n",
    "        replace_with_currency_symbol=\"\",\n",
    "        # lang=\"en\"                       # set to 'de' for German special handling\n",
    "    )\n",
    "    tag_pattern = re.compile(\"@\\S+\")\n",
    "    dot_pattern = re.compile(\"\\.{2,}\")\n",
    "    text = tag_pattern.sub(r'', text)  # —É–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏ —é–∑–µ—Ä–æ–≤\n",
    "    text = dot_pattern.sub(r'', text)  # —É–±–∏—Ä–∞–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏—è (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, —Ç–∫ –∏—Ö –º–Ω–æ–≥–æ)\n",
    "    text = remove_emoticons(text, emot_core)  # —É–±–∏—Ä–∞–µ–º —ç–º–æ—Ç–∏–∫–æ–Ω—ã —Ç–∏–ø–∞ :) :-(((\n",
    "    text = num2words_with_extract(text)  # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ü–∏—Ñ—Ä—ã –≤ —Ç–µ–∫—Å—Ç\n",
    "    return \" \".join(text.split())  # normalize whitespaces\n",
    "\n",
    "\n",
    "# –ø—Ä–∏–º–µ—Ä –æ—Ç—Ä–∞–±–æ—Ç–∫–∏\n",
    "clean_text(\n",
    "    \"@varlamov @McFa__ul bortnikov@mail.ru –ù–∞ –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ ::-( :333 100 .......... —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co/ZwOHPDKUqq 88005553535\",\n",
    "    emot_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing pickle\n"
     ]
    }
   ],
   "source": [
    "twitter_cut = None\n",
    "csv_path = Path(\"csv\")\n",
    "twitter_full_path = csv_path / \"twitter_full.csv\"\n",
    "twitter_cut_path = csv_path / \"twitter_cut.pickle\"\n",
    "\n",
    "twitter = pd.read_csv(twitter_full_path)\n",
    "\n",
    "if not os.path.exists(twitter_cut_path):\n",
    "    print(\"Clearing initial csv and saving to pickle\")\n",
    "    twitter_cut = twitter.drop([\"id\", \"Unnamed: 0\"], inplace=False, axis=1)  # .rename(columns={\"Unnamed: 0\": \"index\"})\n",
    "    twitter_cut = twitter_cut[twitter_cut[\"label\"] != \"skip\"]\n",
    "    twitter_cut = twitter_cut.reset_index()\n",
    "    twitter_cut.rename(columns={\"index\": \"old_idx\"}, inplace=True)\n",
    "    twitter_cut[\"text_clean\"] = twitter_cut[\"text\"].apply(clean_text)\n",
    "    twitter_cut.to_pickle(twitter_cut_path)\n",
    "else:\n",
    "    print(\"Loading existing pickle\")\n",
    "    twitter_cut = pd.read_pickle(\"./csv/twitter_cut.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# twitter.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>negative</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å—Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...</td>\n",
       "      <td>negative</td>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\" (—Å) –∞—Ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>–û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ,–∞ —Ç–∞–º –¥—Ä—É–≥–æ–µ.–æ —Å–±–æ—Ä–µ –¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@idkwhht –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞üò≥üò≥üò≥</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>110</td>\n",
       "      <td>@snakey_ssnake –î–µ–ª–∞—Ç—å –µ—â–µ ‚ï∞(‚Äµ‚ñ°‚Ä≤)‚ïØ (–º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏...</td>\n",
       "      <td>positive</td>\n",
       "      <td>–¥–µ–ª–∞—Ç—å –µ—â–µ ‚ï∞(‚Äµ‚ñ°‚Ä≤)‚ïØ (–º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>112</td>\n",
       "      <td>@cerealporridge üò≠üò≠üò≠üò≠‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è —Å–ø–∞—Å–∏–±–æ üò≠‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è</td>\n",
       "      <td>speech</td>\n",
       "      <td>—Å–ø–∞—Å–∏–±–æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>114</td>\n",
       "      <td>–í –°–µ–≤–ì–£ –ø—Ä–æ—à–µ–ª –∫—Ä—É–≥–ª—ã–π —Å—Ç–æ–ª –ø–æ —Å–ª—É—á–∞—é –î–Ω—è —Å–æ–ª–∏...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–≤ —Å–µ–≤–≥—É –ø—Ä–æ—à–µ–ª –∫—Ä—É–≥–ª—ã–π —Å—Ç–æ–ª –ø–æ —Å–ª—É—á–∞—é –¥–Ω—è —Å–æ–ª–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>115</td>\n",
       "      <td>@great_knee –ë—Ä–æ,–º–æ—è —Ç–æ–∂–µ</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–±—Ä–æ,–º–æ—è —Ç–æ–∂–µ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>116</td>\n",
       "      <td>@GGuchenko @Ares29014619 @arlig23 @Stepan05244...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–∞ —á—Ç–æ —Ç—ã —Ç–∞–∫ –ø–µ—Ä–µ–ø—É–≥–∞–ª—Å—è —Ç–æ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    old_idx                                               text     label  \\\n",
       "0         1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...  negative   \n",
       "1         2  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...  negative   \n",
       "2         3  –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...   neutral   \n",
       "3         4  @Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...   neutral   \n",
       "4         5      @idkwhht –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞üò≥üò≥üò≥   neutral   \n",
       "..      ...                                                ...       ...   \n",
       "95      110  @snakey_ssnake –î–µ–ª–∞—Ç—å –µ—â–µ ‚ï∞(‚Äµ‚ñ°‚Ä≤)‚ïØ (–º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏...  positive   \n",
       "96      112     @cerealporridge üò≠üò≠üò≠üò≠‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è —Å–ø–∞—Å–∏–±–æ üò≠‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è    speech   \n",
       "97      114  –í –°–µ–≤–ì–£ –ø—Ä–æ—à–µ–ª –∫—Ä—É–≥–ª—ã–π —Å—Ç–æ–ª –ø–æ —Å–ª—É—á–∞—é –î–Ω—è —Å–æ–ª–∏...   neutral   \n",
       "98      115                           @great_knee –ë—Ä–æ,–º–æ—è —Ç–æ–∂–µ   neutral   \n",
       "99      116  @GGuchenko @Ares29014619 @arlig23 @Stepan05244...   neutral   \n",
       "\n",
       "                                           text_clean  \n",
       "0   –≤–µ–ª–ª –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å—Ç...  \n",
       "1   \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\" (—Å) –∞—Ä...  \n",
       "2                     –æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã  \n",
       "3   –Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ,–∞ —Ç–∞–º –¥—Ä—É–≥–æ–µ.–æ —Å–±–æ—Ä–µ –¥...  \n",
       "4                   –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞  \n",
       "..                                                ...  \n",
       "95               –¥–µ–ª–∞—Ç—å –µ—â–µ ‚ï∞(‚Äµ‚ñ°‚Ä≤)‚ïØ (–º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å)  \n",
       "96                                            —Å–ø–∞—Å–∏–±–æ  \n",
       "97  –≤ —Å–µ–≤–≥—É –ø—Ä–æ—à–µ–ª –∫—Ä—É–≥–ª—ã–π —Å—Ç–æ–ª –ø–æ —Å–ª—É—á–∞—é –¥–Ω—è —Å–æ–ª–∏...  \n",
       "98                                       –±—Ä–æ,–º–æ—è —Ç–æ–∂–µ  \n",
       "99                       –∞ —á—Ç–æ —Ç—ã —Ç–∞–∫ –ø–µ—Ä–µ–ø—É–≥–∞–ª—Å—è —Ç–æ?  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_cut.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>num_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>negative</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å—Ç...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...</td>\n",
       "      <td>negative</td>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\" (—Å) –∞—Ä...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>–û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ,–∞ —Ç–∞–º –¥—Ä—É–≥–æ–µ.–æ —Å–±–æ—Ä–µ –¥...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@idkwhht –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞üò≥üò≥üò≥</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11544</th>\n",
       "      <td>13386</td>\n",
       "      <td>–≠—Ç–æ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–º–æ–∫–æ–¥ –∏ –æ–Ω –æ–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π! https://...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>—ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–º–æ–∫–æ–¥ –∏ –æ–Ω –æ–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11545</th>\n",
       "      <td>13387</td>\n",
       "      <td>–≤—Å–µ –ø–æ—Ä–∞ —Å–ø–∞—Ç—å –ø–∏–∑–¥–µ—Ü —Å–ª–æ–≤–∏–ª–∞ —à–∏–∑—É</td>\n",
       "      <td>negative</td>\n",
       "      <td>–≤—Å–µ –ø–æ—Ä–∞ —Å–ø–∞—Ç—å –ø–∏–∑–¥–µ—Ü —Å–ª–æ–≤–∏–ª–∞ —à–∏–∑—É</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11546</th>\n",
       "      <td>13388</td>\n",
       "      <td>—Ç–∞–∫–∏–º–∏ —Ç–µ–º–ø–∞–º–∏ —è —Å–æ–∑–¥–∞–º –Ω–æ–≤—É—é —Å–µ–∫—Ç—É –∏–ª–∏ –æ—Ä–≥–∞–Ω–∏...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>—Ç–∞–∫–∏–º–∏ —Ç–µ–º–ø–∞–º–∏ —è —Å–æ–∑–¥–∞–º –Ω–æ–≤—É—é —Å–µ–∫—Ç—É –∏–ª–∏ –æ—Ä–≥–∞–Ω–∏...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>13389</td>\n",
       "      <td>–¢—ã —Å–º–æ—Ç—Ä–µ–ª–∞ –∞–Ω–∏–º–µ, –∑–∞–≤–µ—Ä–Ω—É–≤—à–∏—Å—å –≤ –æ–¥–µ—è–ª–æ ,–ø–æ–∫–∞...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>—Ç—ã —Å–º–æ—Ç—Ä–µ–ª–∞ –∞–Ω–∏–º–µ, –∑–∞–≤–µ—Ä–Ω—É–≤—à–∏—Å—å –≤ –æ–¥–µ—è–ª–æ ,–ø–æ–∫–∞...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11548</th>\n",
       "      <td>13390</td>\n",
       "      <td>@AlyonaPikachu –ü–∏–∑–¥–∞–Ω—É—Ç—å—Å—è</td>\n",
       "      <td>negative</td>\n",
       "      <td>–ø–∏–∑–¥–∞–Ω—É—Ç—å—Å—è</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11549 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       old_idx                                               text     label  \\\n",
       "0            1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...  negative   \n",
       "1            2  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...  negative   \n",
       "2            3  –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...   neutral   \n",
       "3            4  @Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...   neutral   \n",
       "4            5      @idkwhht –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞üò≥üò≥üò≥   neutral   \n",
       "...        ...                                                ...       ...   \n",
       "11544    13386  –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–º–æ–∫–æ–¥ –∏ –æ–Ω –æ–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π! https://...   neutral   \n",
       "11545    13387                 –≤—Å–µ –ø–æ—Ä–∞ —Å–ø–∞—Ç—å –ø–∏–∑–¥–µ—Ü —Å–ª–æ–≤–∏–ª–∞ —à–∏–∑—É  negative   \n",
       "11546    13388  —Ç–∞–∫–∏–º–∏ —Ç–µ–º–ø–∞–º–∏ —è —Å–æ–∑–¥–∞–º –Ω–æ–≤—É—é —Å–µ–∫—Ç—É –∏–ª–∏ –æ—Ä–≥–∞–Ω–∏...   neutral   \n",
       "11547    13389  –¢—ã —Å–º–æ—Ç—Ä–µ–ª–∞ –∞–Ω–∏–º–µ, –∑–∞–≤–µ—Ä–Ω—É–≤—à–∏—Å—å –≤ –æ–¥–µ—è–ª–æ ,–ø–æ–∫–∞...   neutral   \n",
       "11548    13390                         @AlyonaPikachu –ü–∏–∑–¥–∞–Ω—É—Ç—å—Å—è  negative   \n",
       "\n",
       "                                              text_clean  num_label  \n",
       "0      –≤–µ–ª–ª –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å—Ç...          0  \n",
       "1      \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\" (—Å) –∞—Ä...          0  \n",
       "2                        –æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã          1  \n",
       "3      –Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ,–∞ —Ç–∞–º –¥—Ä—É–≥–æ–µ.–æ —Å–±–æ—Ä–µ –¥...          1  \n",
       "4                      –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞          1  \n",
       "...                                                  ...        ...  \n",
       "11544              —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–º–æ–∫–æ–¥ –∏ –æ–Ω –æ–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π!          1  \n",
       "11545                 –≤—Å–µ –ø–æ—Ä–∞ —Å–ø–∞—Ç—å –ø–∏–∑–¥–µ—Ü —Å–ª–æ–≤–∏–ª–∞ —à–∏–∑—É          0  \n",
       "11546  —Ç–∞–∫–∏–º–∏ —Ç–µ–º–ø–∞–º–∏ —è —Å–æ–∑–¥–∞–º –Ω–æ–≤—É—é —Å–µ–∫—Ç—É –∏–ª–∏ –æ—Ä–≥–∞–Ω–∏...          1  \n",
       "11547  —Ç—ã —Å–º–æ—Ç—Ä–µ–ª–∞ –∞–Ω–∏–º–µ, –∑–∞–≤–µ—Ä–Ω—É–≤—à–∏—Å—å –≤ –æ–¥–µ—è–ª–æ ,–ø–æ–∫–∞...          1  \n",
       "11548                                        –ø–∏–∑–¥–∞–Ω—É—Ç—å—Å—è          0  \n",
       "\n",
       "[11549 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_to_int(label):\n",
    "    if label == 'negative':\n",
    "        return 0\n",
    "    elif label == 'neutral' or label == 'speech':\n",
    "        return 1\n",
    "    elif label == 'positive':\n",
    "        return 2\n",
    "\n",
    "\n",
    "twitter_cut[\"num_label\"] = twitter_cut[\"label\"].apply(label_to_int)\n",
    "\n",
    "twitter_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'neg'), Text(1, 0, 'neu'), Text(2, 0, 'pos')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(data=twitter_cut, x=\"num_label\")\n",
    "ax.set_xticklabels([\"neg\", \"neu\", \"pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ò–∑-–∑–∞ —Ç–æ–≥–æ, —á—Ç–æ speech —É—à–µ–ª –≤ neutral, —Ç–æ —É –Ω–∞—Å –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å (–≤–æ–∑–º–æ–∂–Ω–æ —Å —ç—Ç–∏–º —Å—Ç–æ–∏–ª–æ —á—Ç–æ-—Ç–æ —Å–¥–µ–ª–∞—Ç—å)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º –¥–∏—Å—Ç–∏–ª–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å https://habr.com/ru/articles/562064/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model_name_or_path=\"cointegrated/rubert-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_tiny(text):\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return pd.Series([encoding[\"input_ids\"], encoding[\"attention_mask\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–í—Ä–æ–¥–µ –∫–∞–∫ –º–æ–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π –∫–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞, –Ω–æ –≤—Ä–æ–¥–µ –∫–∞–∫ –º–æ–∂–Ω–æ –∏ –Ω–µ –ø–∏—Å–∞—Ç—å, —Ç–∞–∫ –∏ –Ω–µ –ø–æ–Ω—è–ª –ø–æ–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_cut_tiny = twitter_cut.copy()\n",
    "twitter_cut_tiny[[\"input_ids\", \"attention_mask\"]] = twitter_cut_tiny[\"text_clean\"].apply(tokenize_tiny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Ç—Ä–µ–π–Ω/—Ç–µ—Å—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    twitter_cut_tiny,\n",
    "    test_size=SPLIT_SIZE,\n",
    "    shuffle=True,\n",
    "    stratify=twitter_cut_tiny['num_label'].values,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "train_dataset, test_dataset, train_dataloader, test_dataloader = helper.prepare_ds_dl_transformer(\n",
    "    train_dataframe=train_df,\n",
    "    test_dataframe=test_df,\n",
    "    label_field_name=\"num_label\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## –ö–∏–¥–∞–µ–º –≤—Å–µ —ç—Ç–æ –≤ –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1 = torchmetrics.F1Score(\n",
    "    task=\"multiclass\",\n",
    "    num_classes=3,\n",
    "    device=device\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# –ó–∞–º–µ—Ç–∫–∞ –¥–ª—è —Å–µ–±—è - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—É—Ç https://huggingface.co/transformers/v2.9.1/main_classes/configuration.html\n",
    "\n",
    "def rubert_tiny_trainer(\n",
    "        epochs: int,\n",
    "        lr: float,\n",
    "        file_name: typing.AnyStr,\n",
    "        force_override: bool,\n",
    "        scheduler_gamma: float or None = None,\n",
    "        model: BertForSequenceClassification = None,\n",
    "):\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "    rubert = None\n",
    "    if model is None:\n",
    "        rubert = BertForSequenceClassification.from_pretrained(\n",
    "            pretrained_model_name_or_path=\"cointegrated/rubert-tiny\",\n",
    "            num_labels=3,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "        )\n",
    "    else:\n",
    "        rubert = model\n",
    "\n",
    "    rubert.to(device)\n",
    "    rubert.name = file_name\n",
    "\n",
    "    rubert_optimizer = torch.optim.AdamW(\n",
    "        rubert.parameters(),\n",
    "        lr=lr,\n",
    "    )\n",
    "    scheduler = None\n",
    "    if scheduler_gamma is not None:\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer=rubert_optimizer,\n",
    "            gamma=scheduler_gamma,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    return helper.model_trainer_with_saving(\n",
    "        model=rubert,\n",
    "        epochs=epochs,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        loss_function=None,\n",
    "        optimizer=rubert_optimizer,\n",
    "        eval_function=f1,\n",
    "        device=device,\n",
    "        file_name=file_name,\n",
    "        scheduler=scheduler,\n",
    "        transformer=True,\n",
    "        force_override=force_override,\n",
    "        models_folder='models',\n",
    "        res_folder='model_res'\n",
    "    )\n",
    "\n",
    "\n",
    "class_names = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "\n",
    "def tiny_results_show(model, results):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    helper.model_eval_report(\n",
    "        model=model,\n",
    "        test_dataloader=test_dataloader,\n",
    "        test_dataset=test_dataset,\n",
    "        loss_function=None,\n",
    "        eval_function=f1,\n",
    "        device=device,\n",
    "        transformer=True,\n",
    "        class_names=class_names\n",
    "    )\n",
    "    # plt.rcParams['figure.figsize'] = [6, 5]\n",
    "    ax1.plot(results.history_test_loss[0], label='test_loss')\n",
    "    ax1.plot(results.history_train_loss[0], label='train_loss')\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "    # plt.rcParams['figure.figsize'] = [6, 5]\n",
    "    ax2.plot(results.history_test_eval[0], label='test_eval')\n",
    "    ax2.plot(results.history_train_eval[0], label='train_eval')\n",
    "    ax2.set_title('eval')\n",
    "    ax2.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_tiny1, rubert_tiny_results1 = rubert_tiny_trainer(\n",
    "    epochs=15,\n",
    "    lr=3e-5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_tiny_ep15_lr3e-5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ö–∞–∫ –º–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å - —Å–∞–º–æ–º—É –¥–æ–±–∞–≤–ª—è—Ç—å —Å–ª–æ–∏ –Ω–µ –ø—Ä–∏—à–ª–æ—Å—å, –Ω–∞ –≤—ã—Ö–æ–¥–µ 3 —Ñ–∏—á–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ù–∞–±–ª—é–¥–∞–µ–º –æ—á–µ–≤–∏–¥–Ω–µ–π—à–∏–π –æ–≤–µ—Ä—Ñ–∏—Ç?... –ü–æ–ø—Ä–æ–±—É—é —É–º–µ–Ω—å—à–∏—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_results_show(\n",
    "    rubert_tiny1,\n",
    "    rubert_tiny_results1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_tiny2, rubert_tiny_results2 = rubert_tiny_trainer(\n",
    "    epochs=15,\n",
    "    lr=3e-6,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_tiny_ep15_lr3e-6\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_results_show(\n",
    "    rubert_tiny2,\n",
    "    rubert_tiny_results2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ–ª—É—á—à–µ, –Ω–æ –≤—Å–µ —Ä–∞–≤–Ω–æ –≥–ª–æ—Ö–Ω–µ—Ç –Ω–∞ 65%, –ø–æ–ø—Ä–æ–±—É—é —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–æ–±–∞–≤–∏—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.0000e-05.\n",
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_tiny3, rubert_tiny_results3 = rubert_tiny_trainer(\n",
    "    epochs=15,\n",
    "    lr=3e-5,\n",
    "    scheduler_gamma=0.5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_tiny_ep15_lr3e-5_gamma50\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª—É—á—à–µ, –Ω–æ –≥–∞–º–º–∞ –±—É–¥—Ç–æ –±–æ–ª—å—à–∞—è, –≥–∞—Å–∏—Ç—Å—è —Ä–∞–Ω—å—à–µ –ø–æ–ª–æ–∂–µ–Ω–Ω–æ–≥–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_results_show(\n",
    "    rubert_tiny3,\n",
    "    rubert_tiny_results3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.0000e-05.\n",
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_tiny4, rubert_tiny_results4 = rubert_tiny_trainer(\n",
    "    epochs=15,\n",
    "    lr=3e-5,\n",
    "    scheduler_gamma=0.75,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_tiny_ep15_lr3e-5_gamma75\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_results_show(\n",
    "    rubert_tiny4,\n",
    "    rubert_tiny_results4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü—Ä–∏–º–µ—Ä–Ω–æ —Ç–æ –∂–µ —Å–∞–º–æ–µ, –Ω–æ –ª–æ—Å—Å –Ω–∞ —Ç–µ—Å—Ç–µ —Ä–æ—Å, –ø–æ—ç—Ç–æ–º—É 0.5 –≥–∞–º–º—ã –±—ã–ª–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –≤–∏–¥–∏–º–æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Check overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_tiny_OF, rubert_tiny_results_OF = rubert_tiny_trainer(\n",
    "    epochs=50,\n",
    "    lr=5e-6,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_tiny_ep50_lr5e-6_OVERFIT_TEST\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_results_show(\n",
    "    rubert_tiny_OF,\n",
    "    rubert_tiny_results_OF\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Double descend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–í –æ–±—â–µ–º –Ω–∞ –ª–µ–∫—Ü–∏–∏ –Ω–∞–º —Ä–∞—Å–∫–∞–∑–∞–ª–∏ –ø—Ä–æ —ç—Ñ—Ñ–µ–∫—Ç –¥–≤–æ–π–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞, –º–µ–Ω—è —ç—Ç–æ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–ª–æ, –ø—Ä–æ—á–∏—Ç–∞–ª –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –±—É–º–∞–≥—É –∏ —Ä–µ—à–∏–ª –ø—Ä–æ–≤–µ—Ä–∏—Ç—å. –ö–∏–Ω—É–ª –Ω–∞ 5000 —ç–ø–æ—Ö, –æ—Å—Ç–∞–≤–∏–ª –∫–æ–ø—Ç–∏—Ç—å—Å—è –Ω–∞ ~6 —á–∞—Å–æ–≤, –≤ –∏—Ç–æ–≥–µ –∫–æ–º–ø—å—é—Ç–µ—Ä —Å–∫–∏—Å —Å –±–ª—É—Å–∫—Ä–∏–Ω–æ–º –Ω–∞ 3000 —ç–ø–æ—Ö–µ. –ü–æ–≤–µ–¥–µ–Ω–∏—è –¥–≤–æ–π–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞ –Ω–µ –±—ã–ª–æ, —Ç–µ—Å—Ç–ª–æ—Å—Å –ø—Ä–æ–¥–æ–ª–∂–∞–ª —Ä–æ—Å—Ç–∏ –∏ –Ω–∏–∫–∞–∫ –Ω–µ —Ö–æ—Ç–µ–ª —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞—Ç—å—Å—è –æ–±—Ä–∞—Ç–Ω–æ. –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –¥–∏—Å—Ç–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –æ–≤–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∏ –Ω—É–∂–Ω–æ –±—Ä–∞—Ç—å –±–µ—Ä—Ç/–±–µ—Ä—Ç–ª–∞—Ä–¥–∂ –¥–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∞. –í —Å—Ç–æ—Ä–æ–Ω—É –∏–º–µ–Ω–Ω–æ –±–µ—Ä—Ç–∞ –Ω–µ –∫–æ–ø–∞–ª, –Ω–æ –ø–æ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–µ —ç—Ñ—Ñ–µ–∫—Ç –¥–æ–ª–∂–µ–Ω –Ω–∞–±–ª—é–¥–∞—Ç—å—Å—è –∏ —É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rubert_tiny, rubert_tiny_results = rubert_tiny_trainer(\n",
    "#     epochs=5000,\n",
    "#     lr=3e-6,\n",
    "#     force_override=False,\n",
    "#     file_name=\"rubert_tiny_ep5000_lr3e-6\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rubert_tiny_results_show(\n",
    "#     rubert_tiny,\n",
    "#     rubert_tiny_results\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "—Å–æ—Å—Ç–∞–≤–∏–º —Ç–∞–±–ª–∏—á–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ rubert_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>status</th>\n",
       "      <th>epochs_remain</th>\n",
       "      <th>on_which_batch_broken</th>\n",
       "      <th>train_time</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>eval_function</th>\n",
       "      <th>device</th>\n",
       "      <th>end_test_loss</th>\n",
       "      <th>end_test_eval</th>\n",
       "      <th>end_train_loss</th>\n",
       "      <th>end_train_eval</th>\n",
       "      <th>history_test_loss</th>\n",
       "      <th>history_test_eval</th>\n",
       "      <th>history_train_loss</th>\n",
       "      <th>history_train_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_ep15_lr3e-5</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>TrainStatus.Success</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>84.419073</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>3.000000e-05</td>\n",
       "      <td>MulticlassF1Score</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1.498644</td>\n",
       "      <td>0.648159</td>\n",
       "      <td>0.122758</td>\n",
       "      <td>0.959536</td>\n",
       "      <td>[0.81073, 0.77603, 0.7722, 0.78766, 0.82281, 0...</td>\n",
       "      <td>[0.63781, 0.65775, 0.66922, 0.6718, 0.67094, 0...</td>\n",
       "      <td>[0.92728, 0.76131, 0.68418, 0.61027, 0.54613, ...</td>\n",
       "      <td>[0.56902, 0.67354, 0.71821, 0.75472, 0.79079, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_ep15_lr3e-6</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>TrainStatus.Success</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>80.687391</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>3.000000e-06</td>\n",
       "      <td>MulticlassF1Score</td>\n",
       "      <td>cuda</td>\n",
       "      <td>0.787649</td>\n",
       "      <td>0.645993</td>\n",
       "      <td>0.719137</td>\n",
       "      <td>0.695405</td>\n",
       "      <td>[1.02799, 0.99297, 0.96351, 0.92789, 0.89032, ...</td>\n",
       "      <td>[0.50707, 0.52039, 0.53832, 0.55995, 0.59566, ...</td>\n",
       "      <td>[1.06019, 1.00558, 0.97351, 0.93928, 0.90197, ...</td>\n",
       "      <td>[0.48434, 0.51294, 0.54049, 0.5626, 0.58841, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_ep15_lr3e-5_gamma50</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>TrainStatus.Success</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>80.672499</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>9.155273e-10</td>\n",
       "      <td>MulticlassF1Score</td>\n",
       "      <td>cuda</td>\n",
       "      <td>0.778388</td>\n",
       "      <td>0.659627</td>\n",
       "      <td>0.676965</td>\n",
       "      <td>0.719121</td>\n",
       "      <td>[0.81073, 0.78908, 0.78093, 0.7806, 0.78153, 0...</td>\n",
       "      <td>[0.63781, 0.64628, 0.64886, 0.65259, 0.65431, ...</td>\n",
       "      <td>[0.92728, 0.76537, 0.72155, 0.69749, 0.69167, ...</td>\n",
       "      <td>[0.56902, 0.67488, 0.69669, 0.70413, 0.71104, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_ep15_lr3e-5_gamma75</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>TrainStatus.Success</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>81.819096</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4.009038e-07</td>\n",
       "      <td>MulticlassF1Score</td>\n",
       "      <td>cuda</td>\n",
       "      <td>0.810899</td>\n",
       "      <td>0.666794</td>\n",
       "      <td>0.528303</td>\n",
       "      <td>0.798641</td>\n",
       "      <td>[0.81073, 0.78125, 0.77734, 0.77857, 0.7876, 0...</td>\n",
       "      <td>[0.63781, 0.64985, 0.65889, 0.66724, 0.66609, ...</td>\n",
       "      <td>[0.92728, 0.7626, 0.70039, 0.65345, 0.62534, 0...</td>\n",
       "      <td>[0.56902, 0.67421, 0.70677, 0.72994, 0.74978, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name                     class_name  \\\n",
       "0          rubert_tiny_ep15_lr3e-5  BertForSequenceClassification   \n",
       "0          rubert_tiny_ep15_lr3e-6  BertForSequenceClassification   \n",
       "0  rubert_tiny_ep15_lr3e-5_gamma50  BertForSequenceClassification   \n",
       "0  rubert_tiny_ep15_lr3e-5_gamma75  BertForSequenceClassification   \n",
       "\n",
       "                status  epochs_remain on_which_batch_broken  train_time  \\\n",
       "0  TrainStatus.Success              0                  None   84.419073   \n",
       "0  TrainStatus.Success              0                  None   80.687391   \n",
       "0  TrainStatus.Success              0                  None   80.672499   \n",
       "0  TrainStatus.Success              0                  None   81.819096   \n",
       "\n",
       "  loss_function optimizer  learning_rate      eval_function device  \\\n",
       "0      NoneType     AdamW   3.000000e-05  MulticlassF1Score   cuda   \n",
       "0      NoneType     AdamW   3.000000e-06  MulticlassF1Score   cuda   \n",
       "0      NoneType     AdamW   9.155273e-10  MulticlassF1Score   cuda   \n",
       "0      NoneType     AdamW   4.009038e-07  MulticlassF1Score   cuda   \n",
       "\n",
       "   end_test_loss  end_test_eval  end_train_loss  end_train_eval  \\\n",
       "0       1.498644       0.648159        0.122758        0.959536   \n",
       "0       0.787649       0.645993        0.719137        0.695405   \n",
       "0       0.778388       0.659627        0.676965        0.719121   \n",
       "0       0.810899       0.666794        0.528303        0.798641   \n",
       "\n",
       "                                   history_test_loss  \\\n",
       "0  [0.81073, 0.77603, 0.7722, 0.78766, 0.82281, 0...   \n",
       "0  [1.02799, 0.99297, 0.96351, 0.92789, 0.89032, ...   \n",
       "0  [0.81073, 0.78908, 0.78093, 0.7806, 0.78153, 0...   \n",
       "0  [0.81073, 0.78125, 0.77734, 0.77857, 0.7876, 0...   \n",
       "\n",
       "                                   history_test_eval  \\\n",
       "0  [0.63781, 0.65775, 0.66922, 0.6718, 0.67094, 0...   \n",
       "0  [0.50707, 0.52039, 0.53832, 0.55995, 0.59566, ...   \n",
       "0  [0.63781, 0.64628, 0.64886, 0.65259, 0.65431, ...   \n",
       "0  [0.63781, 0.64985, 0.65889, 0.66724, 0.66609, ...   \n",
       "\n",
       "                                  history_train_loss  \\\n",
       "0  [0.92728, 0.76131, 0.68418, 0.61027, 0.54613, ...   \n",
       "0  [1.06019, 1.00558, 0.97351, 0.93928, 0.90197, ...   \n",
       "0  [0.92728, 0.76537, 0.72155, 0.69749, 0.69167, ...   \n",
       "0  [0.92728, 0.7626, 0.70039, 0.65345, 0.62534, 0...   \n",
       "\n",
       "                                  history_train_eval  \n",
       "0  [0.56902, 0.67354, 0.71821, 0.75472, 0.79079, ...  \n",
       "0  [0.48434, 0.51294, 0.54049, 0.5626, 0.58841, 0...  \n",
       "0  [0.56902, 0.67488, 0.69669, 0.70413, 0.71104, ...  \n",
       "0  [0.56902, 0.67421, 0.70677, 0.72994, 0.74978, ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubert_tiny_all = pd.concat([rubert_tiny_results1, rubert_tiny_results2, rubert_tiny_results3, rubert_tiny_results4])\n",
    "rubert_tiny_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Rubert-tiny freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ–ø—Ä–æ–±—É—é –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å –≤—Å–µ —Å–ª–æ–∏, –∫—Ä–æ–º–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é—â–µ–≥–æ —Å–ª–æ—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º —Å–ª–æ–∏ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29564, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=312, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubert_tiny_freeze1 = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"cointegrated/rubert-tiny\",\n",
    "    num_labels=3\n",
    ").to(device)\n",
    "\n",
    "rubert_tiny_freeze1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, param in rubert_tiny_freeze1.named_parameters():\n",
    "    if \"classifier\" not in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.0000e-03.\n",
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_tiny_freeze1, rubert_tiny_freeze1_results = rubert_tiny_trainer(\n",
    "    epochs=30,\n",
    "    lr=3e-3,\n",
    "    scheduler_gamma=0.75,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_tiny_freeze_cls_ep15_lr3e-3_gamma75\",\n",
    "    model=rubert_tiny_freeze1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ–ª—É—á–∏–ª–æ—Å—å —Ö—É–∂–µ, —á–µ–º –±–µ–∑ –∑–∞–º–æ—Ä–æ–∑–∫–∏, –Ω–æ –ª—É—á—à–µ, —á–µ–º –±–µ–∑ —Ñ—Ä–∏–∑–∞ –∏ —Å –º–∞–ª–µ–Ω—å–∫–∏–º lr. –ü–æ—Å–º–æ—Ç—Ä–∏–º —á—Ç–æ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_results_show(\n",
    "    rubert_tiny_freeze1,\n",
    "    rubert_tiny_freeze1_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ–ø—Ä–æ–±—É—é –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ —ç–º–±–µ–¥–∏–Ω–≥–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.0000e-04.\n",
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_tiny_freeze2 = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"cointegrated/rubert-tiny\",\n",
    "    num_labels=3\n",
    ").to(device)\n",
    "for name, param in rubert_tiny_freeze2.named_parameters():\n",
    "    if \"embeddings\" not in name and \"classifier\" not in name:\n",
    "        param.requires_grad = False\n",
    "rubert_tiny_freeze2, rubert_tiny_freeze2_results = rubert_tiny_trainer(\n",
    "    epochs=30,\n",
    "    lr=8e-4,\n",
    "    scheduler_gamma=0.75,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_tiny_freeze_emb_cls_ep15_lr8e-4_gamma75\",\n",
    "    model=rubert_tiny_freeze2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_results_show(\n",
    "    rubert_tiny_freeze2,\n",
    "    rubert_tiny_freeze2_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–≥—É —Ç–æ–ª—å–∫–æ —Ç–∞–∫ - —Ö–≤–∞—Ç–∏–ª–æ –ø–µ—Ä–≤–æ–≥–æ —ç–ø–æ—Ö–∏ –Ω–∞ –¥–æ–æ–±—É—á–µ–Ω–∏–µ, –ø–æ—Ç–æ–º –º–æ–¥–µ–ª—å –ø–æ—à–ª–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É—é —Ç–µ–ø–µ—Ä—å –≤–º–µ—Å—Ç–æ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å —ç–Ω–∫–æ–¥–µ—Ä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_tiny_freeze3 = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"cointegrated/rubert-tiny\",\n",
    "    num_labels=3\n",
    ").to(device)\n",
    "for name, param in rubert_tiny_freeze3.named_parameters():\n",
    "    if \"encoder\" in name or \"classifier\" in name:\n",
    "        param.requires_grad = False\n",
    "rubert_tiny_freeze3, rubert_tiny_freeze3_results = rubert_tiny_trainer(\n",
    "    epochs=30,\n",
    "    lr=1e-5,\n",
    "    # scheduler_gamma=0.75,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_tiny_freeze_enc_cls_ep15_lr1e-5\",\n",
    "    model=rubert_tiny_freeze3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_results_show(\n",
    "    rubert_tiny_freeze3,\n",
    "    rubert_tiny_freeze3_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç - 66-67% f1, —Ç–æ –µ—Å—Ç—å –≤—Å–µ –∂–µ –∏–¥–µ–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—ã–ª –ø—Ä–∏ —Ä–∞–∑–º–æ—Ä–æ–∑–∫–µ –≤—Å–µ—Ö —Å–ª–æ—ë–≤. –ù–∞ —ç—Ç–æ–º —Å –¥–∏—Å—Ç–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é –º–æ–∂–Ω–æ –∑–∞–∫–æ–Ω—á–∏—Ç—å –∏ –ø–µ—Ä–µ–π—Ç–∏ –∫ –ø–æ–ª–Ω–æ—Ä–∞–∑–º–µ—Ä–Ω–æ–π rubert, –∫–æ—Ç–æ—Ä–∞—è –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ bert-base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –£ –º–µ–Ω—è –≥–¥–µ-—Ç–æ —Ç–µ—á–µ—Ç –ø–∞–º—è—Ç—å –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–µ, –∏ —ç—Ç–æ –¥–∞–∂–µ –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç –æ—Å–æ–±–æ(( –í–æ–∑–º–æ–∂–Ω–æ –º–æ–¥–µ–ª–∏ –æ—Å—Ç–∞—é—Ç—Å—è –Ω–∞ –≤–∏–¥—é—Ö–µ –∏ –Ω–µ —Ö–æ—Ç—è—Ç —É—Ö–æ–¥–∏—Ç—å, –ø–æ—Ç–æ–º—É —á—Ç–æ –≥–¥–µ-—Ç–æ –µ—â–µ –≤–∏—Å–∏—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –Ω–∏—Ö\n",
    "\n",
    "del rubert_tiny1\n",
    "del rubert_tiny2\n",
    "del rubert_tiny3\n",
    "del rubert_tiny4\n",
    "del rubert_tiny_freeze1\n",
    "del rubert_tiny_freeze2\n",
    "del rubert_tiny_freeze3\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Rubert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>num_label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>negative</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å—Ç...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(12044), tensor(343), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...</td>\n",
       "      <td>negative</td>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\" (—Å) –∞—Ä...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(108), tensor(67121), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>–û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(7537), tensor(1976), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ,–∞ —Ç–∞–º –¥—Ä—É–≥–æ–µ.–æ —Å–±–æ—Ä–µ –¥...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(801), tensor(57939), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@idkwhht –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞üò≥üò≥üò≥</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(995), tensor(1187), tens...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>–°—á–∞—Å—Ç—å—è –∑–¥–æ—Ä–æ–≤—å—è 10 –∫–ª–∞—Å—Å–Ω–∏–∫–∞–º https://t.co/M9...</td>\n",
       "      <td>speech</td>\n",
       "      <td>—Å—á–∞—Å—Ç—å—è –∑–¥–æ—Ä–æ–≤—å—è –¥–µ—Å—è—Ç—å –∫–ª–∞—Å—Å–Ω–∏–∫–∞–º</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(14053), tensor(9165), te...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>@dntbliev –ù–ï –ü–ê–õ–ò.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–Ω–µ –ø–∞–ª–∏.</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(802), tensor(41952), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>@BTS_twt —Ç—ã —Ç–∞–∫–æ–π –∫—Ä–∞—Å–∏–≤—ã–π üò≠üò≠üò≠ü•∫üíì</td>\n",
       "      <td>positive</td>\n",
       "      <td>—Ç—ã —Ç–∞–∫–æ–π –∫—Ä–∞—Å–∏–≤—ã–π</td>\n",
       "      <td>2</td>\n",
       "      <td>[[tensor(101), tensor(1006), tensor(1447), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>@Ladyzchensk –¶—ã–≥–∞–Ω , —Ö—É–ª–µ ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>—Ü—ã–≥–∞–Ω , —Ö—É–ª–µ</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(30607), tensor(128), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>@nikogdanahui1 –° –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è ü•≥ \\r\\n–£—Å–ø–µ—Ö–æ–≤ –∏...</td>\n",
       "      <td>speech</td>\n",
       "      <td>—Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è —É—Å–ø–µ—Ö–æ–≤ –∏ –ø–æ–±–µ–¥ —Ç–µ–±–µ</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(336), tensor(20106), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   old_idx                                               text     label  \\\n",
       "0        1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...  negative   \n",
       "1        2  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...  negative   \n",
       "2        3  –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...   neutral   \n",
       "3        4  @Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...   neutral   \n",
       "4        5      @idkwhht –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞üò≥üò≥üò≥   neutral   \n",
       "5        6  –°—á–∞—Å—Ç—å—è –∑–¥–æ—Ä–æ–≤—å—è 10 –∫–ª–∞—Å—Å–Ω–∏–∫–∞–º https://t.co/M9...    speech   \n",
       "6        7                                 @dntbliev –ù–ï –ü–ê–õ–ò.   neutral   \n",
       "7        8                   @BTS_twt —Ç—ã —Ç–∞–∫–æ–π –∫—Ä–∞—Å–∏–≤—ã–π üò≠üò≠üò≠ü•∫üíì  positive   \n",
       "8        9                      @Ladyzchensk –¶—ã–≥–∞–Ω , —Ö—É–ª–µ ...  negative   \n",
       "9       10  @nikogdanahui1 –° –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è ü•≥ \\r\\n–£—Å–ø–µ—Ö–æ–≤ –∏...    speech   \n",
       "\n",
       "                                          text_clean  num_label  \\\n",
       "0  –≤–µ–ª–ª –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å—Ç...          0   \n",
       "1  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\" (—Å) –∞—Ä...          0   \n",
       "2                    –æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã          1   \n",
       "3  –Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ,–∞ —Ç–∞–º –¥—Ä—É–≥–æ–µ.–æ —Å–±–æ—Ä–µ –¥...          1   \n",
       "4                  –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞          1   \n",
       "5                 —Å—á–∞—Å—Ç—å—è –∑–¥–æ—Ä–æ–≤—å—è –¥–µ—Å—è—Ç—å –∫–ª–∞—Å—Å–Ω–∏–∫–∞–º          1   \n",
       "6                                           –Ω–µ –ø–∞–ª–∏.          1   \n",
       "7                                  —Ç—ã —Ç–∞–∫–æ–π –∫—Ä–∞—Å–∏–≤—ã–π          2   \n",
       "8                                       —Ü—ã–≥–∞–Ω , —Ö—É–ª–µ          0   \n",
       "9               —Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è —É—Å–ø–µ—Ö–æ–≤ –∏ –ø–æ–±–µ–¥ —Ç–µ–±–µ          1   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [[tensor(101), tensor(12044), tensor(343), ten...   \n",
       "1  [[tensor(101), tensor(108), tensor(67121), ten...   \n",
       "2  [[tensor(101), tensor(7537), tensor(1976), ten...   \n",
       "3  [[tensor(101), tensor(801), tensor(57939), ten...   \n",
       "4  [[tensor(101), tensor(995), tensor(1187), tens...   \n",
       "5  [[tensor(101), tensor(14053), tensor(9165), te...   \n",
       "6  [[tensor(101), tensor(802), tensor(41952), ten...   \n",
       "7  [[tensor(101), tensor(1006), tensor(1447), ten...   \n",
       "8  [[tensor(101), tensor(30607), tensor(128), ten...   \n",
       "9  [[tensor(101), tensor(336), tensor(20106), ten...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "1  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "2  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "3  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "4  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "5  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "6  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "7  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "8  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "9  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_base = BertTokenizer.from_pretrained(pretrained_model_name_or_path=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "twitter_cut_base = twitter_cut.copy()\n",
    "\n",
    "\n",
    "def tokenize_base(text):\n",
    "    encoding = tokenizer_base.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return pd.Series([encoding[\"input_ids\"], encoding[\"attention_mask\"]])\n",
    "\n",
    "\n",
    "twitter_cut_base[[\"input_ids\", \"attention_mask\"]] = twitter_cut_base[\"text_clean\"].apply(tokenize_base)\n",
    "\n",
    "train_df_base, test_df_base = train_test_split(\n",
    "    twitter_cut_base,\n",
    "    test_size=SPLIT_SIZE,\n",
    "    shuffle=True,\n",
    "    stratify=twitter_cut_base['num_label'].values,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "train_dataset_base, test_dataset_base, train_dataloader_base, test_dataloader_base = helper.prepare_ds_dl_transformer(\n",
    "    train_dataframe=train_df_base,\n",
    "    test_dataframe=test_df_base,\n",
    "    label_field_name=\"num_label\",\n",
    "    batch_size=16,  # –ü–æ–º–µ–Ω—å—à–µ —á—Ç–æ–± –ø–∞–º—è—Ç—å –Ω–µ —Ç–∞–∫ –±—ã—Å—Ç—Ä–æ —É–ª–µ—Ç–∞–ª–∞ (—Ö–∑ –ø–æ–º–æ–∂–µ—Ç –ª–∏ –≤–æ–æ–±—â–µ)\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "twitter_cut_base.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>num_label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...</td>\n",
       "      <td>negative</td>\n",
       "      <td>–≤–µ–ª–ª –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å—Ç...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(2), tensor(314), tensor(2663), tensor...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...</td>\n",
       "      <td>negative</td>\n",
       "      <td>\"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\" (—Å) –∞—Ä...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(2), tensor(6), tensor(330), tensor(27...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>–û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(2), tensor(23983), tensor(1150), tens...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ,–∞ —Ç–∞–º –¥—Ä—É–≥–æ–µ.–æ —Å–±–æ—Ä–µ –¥...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(2), tensor(548), tensor(650), tensor(...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@idkwhht –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞üò≥üò≥üò≥</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(2), tensor(11521), tensor(19091), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>–°—á–∞—Å—Ç—å—è –∑–¥–æ—Ä–æ–≤—å—è 10 –∫–ª–∞—Å—Å–Ω–∏–∫–∞–º https://t.co/M9...</td>\n",
       "      <td>speech</td>\n",
       "      <td>—Å—á–∞—Å—Ç—å—è –∑–¥–æ—Ä–æ–≤—å—è –¥–µ—Å—è—Ç—å –∫–ª–∞—Å—Å–Ω–∏–∫–∞–º</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(2), tensor(329), tensor(14335), tenso...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>@dntbliev –ù–ï –ü–ê–õ–ò.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–Ω–µ –ø–∞–ª–∏.</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(2), tensor(769), tensor(2189), tensor...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>@BTS_twt —Ç—ã —Ç–∞–∫–æ–π –∫—Ä–∞—Å–∏–≤—ã–π üò≠üò≠üò≠ü•∫üíì</td>\n",
       "      <td>positive</td>\n",
       "      <td>—Ç—ã —Ç–∞–∫–æ–π –∫—Ä–∞—Å–∏–≤—ã–π</td>\n",
       "      <td>2</td>\n",
       "      <td>[[tensor(2), tensor(23101), tensor(14050), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>@Ladyzchensk –¶—ã–≥–∞–Ω , —Ö—É–ª–µ ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>—Ü—ã–≥–∞–Ω , —Ö—É–ª–µ</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(2), tensor(334), tensor(10330), tenso...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>@nikogdanahui1 –° –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è ü•≥ \\r\\n–£—Å–ø–µ—Ö–æ–≤ –∏...</td>\n",
       "      <td>speech</td>\n",
       "      <td>—Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è —É—Å–ø–µ—Ö–æ–≤ –∏ –ø–æ–±–µ–¥ —Ç–µ–±–µ</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(2), tensor(329), tensor(316), tensor(...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   old_idx                                               text     label  \\\n",
       "0        1  –≤–µ–ª–ª –æ–Ω–∏  –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å...  negative   \n",
       "1        2  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\"\\r\\n(—Å)...  negative   \n",
       "2        3  –û–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ü§≠ https://t.co...   neutral   \n",
       "3        4  @Shvonder_chief @dimsmirnov175 –ù–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ ...   neutral   \n",
       "4        5      @idkwhht –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞üò≥üò≥üò≥   neutral   \n",
       "5        6  –°—á–∞—Å—Ç—å—è –∑–¥–æ—Ä–æ–≤—å—è 10 –∫–ª–∞—Å—Å–Ω–∏–∫–∞–º https://t.co/M9...    speech   \n",
       "6        7                                 @dntbliev –ù–ï –ü–ê–õ–ò.   neutral   \n",
       "7        8                   @BTS_twt —Ç—ã —Ç–∞–∫–æ–π –∫—Ä–∞—Å–∏–≤—ã–π üò≠üò≠üò≠ü•∫üíì  positive   \n",
       "8        9                      @Ladyzchensk –¶—ã–≥–∞–Ω , —Ö—É–ª–µ ...  negative   \n",
       "9       10  @nikogdanahui1 –° –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è ü•≥ \\r\\n–£—Å–ø–µ—Ö–æ–≤ –∏...    speech   \n",
       "\n",
       "                                          text_clean  num_label  \\\n",
       "0  –≤–µ–ª–ª –æ–Ω–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —á—Ç–æ –º—É—Å–æ—Ä —Ç–∞–∫ —á—Ç–æ –Ω–∏—á–µ–≥–æ —Å—Ç...          0   \n",
       "1  \"—Ç—Ä–µ–∑–≤–∞—è –∂–∏–∑–Ω—å –∫–∞–∫–∞—è-—Ç–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—ë–º–Ω–∞—è\" (—Å) –∞—Ä...          0   \n",
       "2                    –æ–π –∫–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã          1   \n",
       "3  –Ω–∞ –∑–∞–±–æ—Ä–µ —Ç–æ–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–æ,–∞ —Ç–∞–º –¥—Ä—É–≥–æ–µ.–æ —Å–±–æ—Ä–µ –¥...          1   \n",
       "4                  –º—ã —Ç–æ–∂–µ –º–µ–±–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É–¥–∂–∏–Ω–∞          1   \n",
       "5                 —Å—á–∞—Å—Ç—å—è –∑–¥–æ—Ä–æ–≤—å—è –¥–µ—Å—è—Ç—å –∫–ª–∞—Å—Å–Ω–∏–∫–∞–º          1   \n",
       "6                                           –Ω–µ –ø–∞–ª–∏.          1   \n",
       "7                                  —Ç—ã —Ç–∞–∫–æ–π –∫—Ä–∞—Å–∏–≤—ã–π          2   \n",
       "8                                       —Ü—ã–≥–∞–Ω , —Ö—É–ª–µ          0   \n",
       "9               —Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è —É—Å–ø–µ—Ö–æ–≤ –∏ –ø–æ–±–µ–¥ —Ç–µ–±–µ          1   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [[tensor(2), tensor(314), tensor(2663), tensor...   \n",
       "1  [[tensor(2), tensor(6), tensor(330), tensor(27...   \n",
       "2  [[tensor(2), tensor(23983), tensor(1150), tens...   \n",
       "3  [[tensor(2), tensor(548), tensor(650), tensor(...   \n",
       "4  [[tensor(2), tensor(11521), tensor(19091), ten...   \n",
       "5  [[tensor(2), tensor(329), tensor(14335), tenso...   \n",
       "6  [[tensor(2), tensor(769), tensor(2189), tensor...   \n",
       "7  [[tensor(2), tensor(23101), tensor(14050), ten...   \n",
       "8  [[tensor(2), tensor(334), tensor(10330), tenso...   \n",
       "9  [[tensor(2), tensor(329), tensor(316), tensor(...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "1  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "2  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "3  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "4  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "5  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "6  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "7  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "8  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "9  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_cut_tiny.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–°—É–¥—è –ø–æ –≤—Å–µ–º—É —Ç–∞–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –ø–æ–¥ –∫–∞–ø–æ—Ç–æ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ–º–µ–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã –∏ –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –º–æ–¥–µ–ª—å –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏ —Ç—Ä–µ–Ω–µ—Ä–∞ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rubert_base_trainer(\n",
    "        epochs: int,\n",
    "        lr: float,\n",
    "        file_name: typing.AnyStr,\n",
    "        force_override: bool,\n",
    "        scheduler_gamma: float or None = None,\n",
    "        model: BertForSequenceClassification = None,\n",
    "        loss_fn=None\n",
    "):\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "    rubert = None\n",
    "    if model is None:\n",
    "        rubert = BertForSequenceClassification.from_pretrained(\n",
    "            pretrained_model_name_or_path=\"blanchefort/rubert-base-cased-sentiment\",\n",
    "            num_labels=3,\n",
    "            return_dict=True,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False\n",
    "        )\n",
    "    else:\n",
    "        rubert = model\n",
    "\n",
    "    rubert.to(device)\n",
    "\n",
    "    rubert.name = file_name\n",
    "\n",
    "    rubert_optimizer = torch.optim.AdamW(\n",
    "        rubert.parameters(),\n",
    "        lr=lr,\n",
    "    )\n",
    "    scheduler = None\n",
    "    if scheduler_gamma is not None:\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer=rubert_optimizer,\n",
    "            gamma=scheduler_gamma,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    return helper.model_trainer_with_saving(\n",
    "        model=rubert,\n",
    "        epochs=epochs,\n",
    "        train_dataloader=train_dataloader_base,\n",
    "        test_dataloader=test_dataloader_base,\n",
    "        loss_function=loss_fn,\n",
    "        optimizer=rubert_optimizer,\n",
    "        eval_function=f1,\n",
    "        device=device,\n",
    "        file_name=file_name,\n",
    "        scheduler=scheduler,\n",
    "        transformer=True,\n",
    "        force_override=force_override,\n",
    "        models_folder='models',\n",
    "        res_folder='model_res'\n",
    "    )\n",
    "\n",
    "\n",
    "def bert_cls_results_show(model, results):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    helper.model_eval_report(\n",
    "        model=model,\n",
    "        test_dataloader=test_dataloader_base,\n",
    "        test_dataset=test_dataset_base,\n",
    "        loss_function=None,\n",
    "        eval_function=f1,\n",
    "        device=device,\n",
    "        transformer=True,\n",
    "        class_names=class_names\n",
    "    )\n",
    "    # plt.rcParams['figure.figsize'] = [6, 5]\n",
    "    ax1.plot(results.history_test_loss[0], label='test_loss')\n",
    "    ax1.plot(results.history_train_loss[0], label='train_loss')\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "    # plt.rcParams['figure.figsize'] = [6, 5]\n",
    "    ax2.plot(results.history_test_eval[0], label='test_eval')\n",
    "    ax2.plot(results.history_train_eval[0], label='train_eval')\n",
    "    ax2.set_title('eval')\n",
    "    ax2.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_model_layers(model):\n",
    "    # Get all of the model's parameters as a list of tuples.\n",
    "    params = list(model.named_parameters())\n",
    "\n",
    "    print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "    print('==== Embedding Layer ====\\n')\n",
    "\n",
    "    for p in params[0:5]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "    for p in params[5:21]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "    for p in params[-4:]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "# rubert_base_freeze1 = BertForSequenceClassification.from_pretrained(\n",
    "#     pretrained_model_name_or_path=\"blanchefort/rubert-base-cased-sentiment\",\n",
    "#     num_labels=3\n",
    "# ).to(device)\n",
    "\n",
    "# for name, param in rubert_base_freeze1.named_parameters():\n",
    "#     if \"classifier\" not in name:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "rubert_base1, rubert_base1_results = rubert_base_trainer(\n",
    "    epochs=4,\n",
    "    lr=2e-5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_ep4_lr2e-5\"\n",
    ")  # –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º –∏–∑ —Å—Ç–∞—Ç—å–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è –±–µ—Ä—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results_show(\n",
    "    rubert_base1,\n",
    "    rubert_base1_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ó–Ω–∞—á–µ–Ω–∏—è –ª—É—á—à–µ, –≤–æ–∑–º–æ–∂–Ω–æ —Å—Ç–æ–∏—Ç –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –µ—â–µ –±–æ–ª—å—à–µ —ç–ø–æ—Ö –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–∫–∏–Ω—É—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "del rubert_base1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.0000e-05.\n",
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_base2, rubert_base2_results = rubert_base_trainer(\n",
    "    epochs=10,\n",
    "    lr=3e-5,\n",
    "    scheduler_gamma=0.90,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_ep10_lr3e-5_gamma90\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results_show(\n",
    "    rubert_base2,\n",
    "    rubert_base2_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü—Ä–µ–æ–¥–æ–ª–µ–ª –ø–æ—Ä–æ–≥ –≤ 66%, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ —Ä–∞–≤–Ω–æ –æ—á–µ–Ω—å —Å–ª–∞–±—ã–µ –¥–ª—è —Ç–∞–∫–æ–π –º–æ–¥–µ–ª–∏. –ù–∞—á–∏–Ω–∞—é –ø–æ–¥–æ–∑—Ä–µ–≤–∞—Ç—å, —á—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –≤ –¥–∞–Ω–Ω—ã—Ö, –∞ –Ω–µ –≤ –º–æ–¥–µ–ª–∏, —Ç–æ —á—Ç–æ neutral –¥–∏–∑–±–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –∏ –æ–Ω–∞ –Ω–µ –º–æ–∂–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ –æ–±—É—á–∏—Ç—å—Å—è. –ü–æ–ø—Ä–æ–±—É—é —Å–¥–µ–ª–∞—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –∫–ª–∞—Å—Å–æ–≤ –∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ –æ–±—É—á–∏—Ç—å rubert-base —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "del rubert_base2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ–ø—Ä–æ–±—É—é —Å–∞–º—ã–π —Ç—É–ø–æ–π –ø–æ–¥—Ö–æ–¥ –±–µ–∑ class weighting - —É–±—Ä–∞—Ç—å –ø–æ–ª–æ–≤–∏–Ω—É –≤—Å–µ—Ö neutral –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'neg'), Text(1, 0, 'neu'), Text(2, 0, 'pos')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –í—Å–ø–æ–º–∏–Ω–∞–µ–º –∫–∞–∫–æ–µ —Å–µ–π—á–∞—Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤\n",
    "ax = sns.countplot(data=twitter_cut, x=\"num_label\")\n",
    "ax.set_xticklabels([\"neg\", \"neu\", \"pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'neg'), Text(1, 0, 'neu'), Text(2, 0, 'pos')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove half of samples with label 1 (neutral) from twitter_cut_base dataset (Copilot request)\n",
    "twitter_cut_base_balanced = twitter_cut_base.drop(\n",
    "    twitter_cut_base[twitter_cut_base.num_label == 1].sample(frac=0.45, random_state=SEED).index)\n",
    "ax = sns.countplot(data=twitter_cut_base_balanced, x=\"num_label\")\n",
    "ax.set_xticklabels([\"neg\", \"neu\", \"pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ò–º–µ–µ–º —Ç–µ–ø–µ—Ä—å +- —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ–±–∏—Ä–∞–µ–º –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df_base_balanced, test_df_base_balanced = train_test_split(\n",
    "    twitter_cut_base_balanced,\n",
    "    test_size=SPLIT_SIZE,\n",
    "    shuffle=True,\n",
    "    stratify=twitter_cut_base_balanced['num_label'].values,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "train_dataset_base_balanced, test_dataset_base_balanced, train_dataloader_base_balanced, test_dataloader_base_balanced = helper.prepare_ds_dl_transformer(\n",
    "    train_dataframe=train_df_base_balanced,\n",
    "    test_dataframe=test_df_base_balanced,\n",
    "    label_field_name=\"num_label\",\n",
    "    batch_size=16,  # –ü–æ–º–µ–Ω—å—à–µ —á—Ç–æ–± –ø–∞–º—è—Ç—å –Ω–µ —Ç–∞–∫ –±—ã—Å—Ç—Ä–æ —É–ª–µ—Ç–∞–ª–∞ (—Ö–∑ –ø–æ–º–æ–∂–µ—Ç –ª–∏ –≤–æ–æ–±—â–µ)\n",
    "    num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rubert_base_balanced_trainer(\n",
    "        epochs: int,\n",
    "        lr: float,\n",
    "        file_name: typing.AnyStr,\n",
    "        force_override: bool,\n",
    "        scheduler_gamma: float or None = None,\n",
    "        model: BertForSequenceClassification = None\n",
    "):\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "    rubert = None\n",
    "    if model is None:\n",
    "        rubert = BertForSequenceClassification.from_pretrained(\n",
    "            pretrained_model_name_or_path=\"blanchefort/rubert-base-cased-sentiment\",\n",
    "            num_labels=3,\n",
    "            return_dict=True,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False\n",
    "        )\n",
    "    else:\n",
    "        rubert = model\n",
    "\n",
    "    rubert.to(device)\n",
    "\n",
    "    rubert.name = file_name\n",
    "\n",
    "    rubert_optimizer = torch.optim.AdamW(\n",
    "        rubert.parameters(),\n",
    "        lr=lr,\n",
    "    )\n",
    "    scheduler = None\n",
    "    if scheduler_gamma is not None:\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer=rubert_optimizer,\n",
    "            gamma=scheduler_gamma,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    return helper.model_trainer_with_saving(\n",
    "        model=rubert,\n",
    "        epochs=epochs,\n",
    "        train_dataloader=train_dataloader_base_balanced,\n",
    "        test_dataloader=test_dataloader_base_balanced,\n",
    "        loss_function=None,\n",
    "        optimizer=rubert_optimizer,\n",
    "        eval_function=f1,\n",
    "        device=device,\n",
    "        file_name=file_name,\n",
    "        scheduler=scheduler,\n",
    "        transformer=True,\n",
    "        force_override=force_override,\n",
    "        models_folder='models',\n",
    "        res_folder='model_res'\n",
    "    )\n",
    "\n",
    "\n",
    "def bert_balanced_cls_results_show(model, results):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    helper.model_eval_report(\n",
    "        model=model,\n",
    "        test_dataloader=test_dataloader_base_balanced,\n",
    "        test_dataset=test_dataset_base_balanced,\n",
    "        loss_function=None,\n",
    "        eval_function=f1,\n",
    "        device=device,\n",
    "        transformer=True,\n",
    "        class_names=class_names\n",
    "    )\n",
    "    # plt.rcParams['figure.figsize'] = [6, 5]\n",
    "    ax1.plot(results.history_test_loss[0], label='test_loss')\n",
    "    ax1.plot(results.history_train_loss[0], label='train_loss')\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "    # plt.rcParams['figure.figsize'] = [6, 5]\n",
    "    ax2.plot(results.history_test_eval[0], label='test_eval')\n",
    "    ax2.plot(results.history_train_eval[0], label='train_eval')\n",
    "    ax2.set_title('eval')\n",
    "    ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_base_balanced1, rubert_base_balanced1_results = rubert_base_balanced_trainer(\n",
    "    epochs=4,\n",
    "    lr=4e-5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_balanced_ep4_lr4e-5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_balanced_cls_results_show(rubert_base_balanced1, rubert_base_balanced1_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–°—Ç–æ–∏—Ç –Ω–∞–≤–µ—Ä–Ω–æ–µ –ø–æ–¥–æ–ª—å—à–µ –ø–æ–æ–±—É—á–∞—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "del rubert_base_balanced1\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_base_balanced2, rubert_base_balanced2_results = rubert_base_balanced_trainer(\n",
    "    epochs=10,\n",
    "    lr=4e-5,\n",
    "    # scheduler_gamma=0.90,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_balanced_ep10_lr4e-5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_balanced_cls_results_show(rubert_base_balanced2, rubert_base_balanced2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ—Å—Ç–∞–≤–ª—é –µ—â–µ –Ω–∞ 10 —ç–ø–æ—Ö (–≤–æ–∑–º–æ–∂–Ω–æ –æ–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ —Å–æ–≤—Å–µ–º —Ç–∞–∫ –∫–∞–∫ —è –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é, –∏ —Ç–æ–≥–¥–∞ –≤—Å–µ –¥–∞–ª—å–Ω–µ–π—à–µ–µ —Å–µ–≥–º–µ–Ω—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - –º—É—Å–æ—Ä)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_base_balanced2, rubert_base_balanced2_results = rubert_base_balanced_trainer(\n",
    "    epochs=10,\n",
    "    lr=3e-5,\n",
    "    # scheduler_gamma=0.90,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_balanced_ep10+10_lr3e-5\",\n",
    "    model=rubert_base_balanced2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_balanced_cls_results_show(rubert_base_balanced2, rubert_base_balanced2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ù–∏—á–µ–≥–æ –æ—Å–æ–±–æ –Ω–µ –ø–æ–º–µ–Ω—è–ª–æ—Å—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–°—Ä–∞–≤–Ω–∏–º —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º (–Ω—É–∂–Ω–æ –∑–∞–Ω–æ–≤–æ –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bert_cls_results_show(rubert_base2, rubert_base2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–í—ã–≤–æ–¥ - –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –≤ –≤–∏–¥–µ —É–¥–∞–ª–µ–Ω–∏—è 50% –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –Ω–µ –¥–∞–µ—Ç –ø—Ä–∏—Ä–æ—Å—Ç–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç —Å–ª–æ–≤–∞ —Å–æ–≤—Å–µ–º. –í –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–∞–∂–µ –±–æ–ª—å—à–µ —Å—Ç–∞–ª–æ –Ω–∞ neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "del rubert_base_balanced2\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Class weights balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1673, 0.6595, 1.5947], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(twitter_cut_base.num_label),\n",
    "                                     y=twitter_cut_base.num_label)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights = class_weights.to(device)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='mean')\n",
    "\n",
    "rubert_base_weighted_balance1, rubert_base_weighted_balance1_results = rubert_base_trainer(\n",
    "    epochs=10,\n",
    "    lr=2e-5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_weighted_balance1_ep10_lr2e-5\",\n",
    "    loss_fn=loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results_show(rubert_base_weighted_balance1, rubert_base_weighted_balance1_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Additional training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_base_weighted_balance1_plus, rubert_base_weighted_balance1_results_plus = rubert_base_trainer(\n",
    "    epochs=10,\n",
    "    lr=8e-6,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_weighted_balance1_ep10_lr2e-5+ep10_lr8e-6\",\n",
    "    loss_fn=loss_function,\n",
    "    model=rubert_base_weighted_balance1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results_show(rubert_base_weighted_balance1_plus, rubert_base_weighted_balance1_results_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ö–æ—Ä–æ—á–µ –±–æ–ª—å—à–µ 67-69 –Ω–µ –≤—ã–∂–∞—Ç—å, –ø–æ—ç—Ç–æ–º—É –¥–µ–ª–∞—é –≤—ã–≤–æ–¥, —á—Ç–æ —Ä–∞–∑–≤–µ—Å–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ –Ω–µ –æ—Å–æ–±–æ —Ç–æ –∏ –ø–æ–º–æ–≥–∞–µ—Ç, –Ω–æ –¥–∞–ª—å—à–µ –ø–æ–ø—Ä–æ–±—É—é –µ—ë –≤—Å–µ –∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å. –Ø —É—Å—Ç–∞–ª –µ—Å–ª–∏ —á–µ—Å—Ç–Ω–æ —ç—Ç–æ –∫–æ–≤—ã—Ä—è—Ç—å, –∏ —É–∂–µ –Ω–µ –ø–æ–Ω–∏–º–∞—é —Å –∫–∞–∫–∏–º –±—É–±–Ω–æ–º –Ω–∞–¥–æ —Ç–∞–Ω—Ü–µ–≤–∞—Ç—å —á—Ç–æ–± 80+ –ø–æ–ª—É—á–∏—Ç—å\n",
    "–í–æ–∑–º–æ–∂–Ω–æ –¥–∞—Ç–∞—Å–µ—Ç –ø—Ä–æ—Å—Ç–æ –Ω–µ—Ö–æ—Ä–æ—à–∏–π, –≤–æ–∑–º–æ–∂–Ω–æ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ, —Ö–∑, –Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –≤–æ–æ–±—â–µ –Ω–µ —Å —á–µ–º, –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é (–ª–∏–±–æ —è –Ω–µ –Ω–∞—à–µ–ª)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "del rubert_base_weighted_balance1\n",
    "del rubert_base_weighted_balance1_plus\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Ruber base layer freezing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ù—É –∏ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—Ä–∞–≤–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç —Ö–æ—Ç—å –∫–∞–∫-—Ç–æ –ø–æ–º–µ–Ω—è—Ç—å —Å–∏—Ç—É–∞—Ü–∏—é - –∑–∞–º–æ—Ä–æ–∑–∫–∞ —Å–ª–æ—ë–≤. –ö–∞–∫ –æ–±—ã—á–Ω–æ, —Å–Ω–∞—á–∞–ª–∞ –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='mean')\n",
    "\n",
    "rubert_base_freeze1 = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"blanchefort/rubert-base-cased-sentiment\",\n",
    "    num_labels=3,\n",
    "    return_dict=True,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "for name, param in rubert_base_freeze1.named_parameters():\n",
    "    if not \"classifier\" in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "rubert_base_freeze1, rubert_base_freeze1_results = rubert_base_trainer(\n",
    "    epochs=10,\n",
    "    lr=1e-5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_freeze_cls_ep10_lr1e-5\",\n",
    "    model=rubert_base_freeze1,\n",
    "    loss_fn=loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results_show(rubert_base_freeze1, rubert_base_freeze1_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ù–∞ —Ç–∞–∫–æ–º –ø—Ä–∏–º–∏—Ç–∏–≤–µ –¥–∞–ª—å—à–µ 60% –Ω–µ —É–µ—Ö–∞—Ç—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ–ø—Ä–æ–±—É—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –≤–µ—Ä—Ö–Ω–∏–µ —Å–ª–æ–∏ –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å, –∫–∞–∫ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (3, 768)\n",
      "classifier.bias                                                 (3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_model_layers(rubert_base_freeze1)\n",
    "rubert_base_freeze1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_base_freeze2 = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"blanchefort/rubert-base-cased-sentiment\",\n",
    "    num_labels=3,\n",
    "    return_dict=True,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "modules = [rubert_base_freeze2.bert.embeddings,\n",
    "           *rubert_base_freeze2.bert.encoder.layer[:6]]  # freezing first 6 out of 12\n",
    "for module in modules:\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "rubert_base_freeze2, rubert_base_freeze2_results = rubert_base_trainer(\n",
    "    epochs=10,\n",
    "    lr=1e-5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_freeze_cls_top6_ep10_lr1e-5\",\n",
    "    model=rubert_base_freeze2,\n",
    "    loss_fn=loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results_show(rubert_base_freeze2, rubert_base_freeze2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–¢–æ–∂–µ —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –º–æ–∂–Ω–æ –µ—â–µ –Ω–∞ 5 —ç–ø–æ—Ö –∫–∏–Ω—É—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_base_freeze2_plus, rubert_base_freeze2_results_plus = rubert_base_trainer(\n",
    "    epochs=5,\n",
    "    lr=3e-5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_freeze_cls_top6_ep10_lr1e-5+ep5_lr1e-5\",\n",
    "    model=rubert_base_freeze2,\n",
    "    loss_fn=loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–í–æ–∑–º–æ–∂–Ω–æ —Ç–∞–º –±—É–¥–µ—Ç –Ω–∞–±–ª—é–¥–∞—Ç—å—Å—è –Ω–µ–∫–æ—Ç–æ—Ä–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å - –ª–æ—Å—Å –ø–∞–¥–∞–µ—Ç –≤ —Ü–µ–ª–æ–º, –ø—Ä–æ–≤–µ—Ä—è—Ç—å —è –Ω–µ –±—É–¥—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results_show(rubert_base_freeze2_plus, rubert_base_freeze2_results_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä—é –µ—â–µ –Ω–∞ —Ç–æ, –µ—Å–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ä–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "rubert_base_freeze3 = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"blanchefort/rubert-base-cased-sentiment\",\n",
    "    num_labels=3,\n",
    "    return_dict=True,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "# freeze like in previos model\n",
    "modules = [*rubert_base_freeze3.bert.encoder.layer[:6]]  # freezing first 6 out of 12\n",
    "for module in modules:\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "rubert_base_freeze3, rubert_base_freeze3_results = rubert_base_trainer(\n",
    "    epochs=10,\n",
    "    lr=2e-5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_freeze_cls_top6_noemb_ep10_lr2e-5\",\n",
    "    model=rubert_base_freeze3,\n",
    "    loss_fn=loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results_show(rubert_base_freeze3, rubert_base_freeze3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–î–æ–æ–±—É—á–∏–º –µ—â–µ 10 —ç–ø–æ—Ö —Å–≤–µ—Ä—Ö—É. –ê –µ—â–µ —è –Ω–µ –ø–æ–Ω–∏–º–∞—é —á–µ–º –æ–±—É—Å–ª–æ–≤–ª–µ–Ω–Ω–∞ —ç—Ç–∞ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≤ —Å–∫–∞—á–∫–∞—Ö. –°–µ–π—á–∞—Å –∑–∞–¥—É–º–∞–ª—Å—è –æ —Ç–æ–º, —á—Ç–æ –∏–∑-–∑–∞ —ç—Ç–∏—Ö —Å–∫–∞—á–∫–æ–≤ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ –≤—Å–µ —ç—Ç–∏ —Ä–∞–∑–±—Ä–æ—Å—ã –ø–æ–ª—É—á–∏–≤—à–∏–µ—Å—è –ø–æ –º–æ–¥–µ–ª—è–º –Ω–∞ +-5% –≤–æ–æ–±—â–µ –Ω–µ –∏–≥—Ä–∞—é—Ç –Ω–∏–∫–∞–∫–æ–π —Ä–æ–ª–∏ –∏ –Ω–∞ –∏—Ö –æ—Å–Ω–æ–≤–µ –Ω–µ–ª—å–∑—è –¥–µ–ª–∞—Ç—å –Ω–∏–∫–∞–∫–∏—Ö –≤—ã–≤–æ–¥–æ–≤. –ù–æ –Ω–µ —Ö–æ—á–µ—Ç—Å—è –æ–± —ç—Ç–æ–º –∑–∞–¥—É–º—ã–≤–∞—Ç—å—Å—è, —Ç–∫ –≤—Ä–µ–º–µ–Ω–∏ –±—ã–ª–æ —É–±–∏—Ç–æ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "# ten more epochs of previous model\n",
    "rubert_base_freeze3_plus, rubert_base_freeze3_results_plus = rubert_base_trainer(\n",
    "    epochs=10,\n",
    "    lr=1e-5,\n",
    "    force_override=False,\n",
    "    file_name=\"rubert_base_freeze_cls_top6_noemb_ep10_lr2e-5+ep10_lr1e-5\",\n",
    "    model=rubert_base_freeze3,\n",
    "    loss_fn=loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results_show(rubert_base_freeze3_plus, rubert_base_freeze3_results_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Summarizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rubert_tiny_results_all = pd.concat([\n",
    "    rubert_tiny_results1,\n",
    "    rubert_tiny_results2,\n",
    "    rubert_tiny_results3,\n",
    "    rubert_tiny_results4\n",
    "])\n",
    "rubert_tiny_freeze_results_all = pd.concat([\n",
    "    rubert_tiny_freeze1_results,\n",
    "    rubert_tiny_freeze2_results,\n",
    "    rubert_tiny_freeze3_results\n",
    "])\n",
    "rubert_base_results_all = pd.concat([\n",
    "    rubert_base1_results,\n",
    "    rubert_base2_results\n",
    "])\n",
    "rubert_base_balanced_all = pd.concat([\n",
    "    rubert_base_balanced1_results,\n",
    "    rubert_base_balanced2_results\n",
    "])\n",
    "rubert_base_weighted_balance_results_all = pd.concat([\n",
    "    rubert_base_weighted_balance1_results,\n",
    "    rubert_base_weighted_balance1_results_plus\n",
    "])\n",
    "rubert_base_freeze_results = pd.concat([\n",
    "    rubert_base_freeze1_results,\n",
    "    rubert_base_freeze2_results,\n",
    "    rubert_base_freeze2_results_plus,\n",
    "    rubert_base_freeze3_results,\n",
    "    rubert_base_freeze3_results_plus\n",
    "])\n",
    "\n",
    "all_results = pd.concat([\n",
    "    rubert_tiny_results_all,\n",
    "    rubert_tiny_freeze_results_all,\n",
    "    rubert_base_results_all,\n",
    "    rubert_base_balanced_all,\n",
    "    rubert_base_weighted_balance_results_all,\n",
    "    rubert_base_freeze_results\n",
    "])\n",
    "all_results_useful = all_results.drop(\n",
    "    columns=['class_name', 'status', 'epochs_remain', 'on_which_batch_broken', 'optimizer', 'eval_function', 'device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—É—á–µ–Ω–∏–µ 1.63 —á–∞—Å–∞, \n",
      "–û–±—É—á–µ–Ω–∏–µ –ø–ª–æ—Ö–∏—Ö 8.15 —á–∞—Å–∞, \n",
      "–ú–æ—ë –æ–±—É—á–µ–Ω–∏–µ 81.55 —á–∞—Å–∞ –∏–ª–∏ 3.40 –¥–Ω–µ–π –∏–ª–∏ 6.80 –¥–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å—É—Ç–æ—á–Ω–æ–≥–æ –±–æ–¥—Ä—Å—Ç–≤–æ–≤–∞–Ω–∏—è\n",
      "–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π 18 —à—Ç—É–∫\n",
      "–ò—Ç–æ–≥–æ–≤—ã–π –ø—Ä–∏—Ä–æ—Å—Ç (–æ—Ç —Ö—É–¥—à–µ–≥–æ) 8.40%\n",
      "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º: 3/10, –æ—á–µ–Ω—å —Ö–æ—Ç–µ–ª 80%+ :(\n"
     ]
    }
   ],
   "source": [
    "# –≤—Å–µ–≥–æ –ø–æ—Ç—Ä–∞—á–µ–Ω–æ —á–∞—Å–æ–≤ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ. –ú–æ–∂–Ω–æ –¥–æ–º–Ω–æ–∂–∏—Ç—å –Ω–∞ 5 —á—Ç–æ–± –ø–æ—Å—á–∏—Ç–∞—Ç—å –≤—Å–µ –∑–∞–ø–æ—Ä–æ—Ç—ã–µ –º–æ–¥–µ–ª–∏. –ò –µ—â–µ –Ω–∞ 10 —á—Ç–æ–± –ø–æ—Å—á–∏—Ç–∞—Ç—å –≤—Å—ë –≤—Ä–µ–º—è —á—Ç–æ–± –¥–æ—Å—Ç–∏—á—å –ø—Ä–∏—Ä–æ—Å—Ç–∞ –≤ 5%((((((\n",
    "hours = (all_results_useful.train_time.sum() / 60 / 60)\n",
    "print(\n",
    "    f'–û–±—É—á–µ–Ω–∏–µ {hours:.2f} —á–∞—Å–∞, \\n–û–±—É—á–µ–Ω–∏–µ –ø–ª–æ—Ö–∏—Ö {hours * 5:.2f} —á–∞—Å–∞, \\n–ú–æ—ë –æ–±—É—á–µ–Ω–∏–µ {hours * 5 * 10:.2f} —á–∞—Å–∞ –∏–ª–∏ {hours * 5 * 10 / 24:.2f} –¥–Ω–µ–π –∏–ª–∏ {hours * 5 * 10 / 12:.2f} –¥–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å—É—Ç–æ—á–Ω–æ–≥–æ –±–æ–¥—Ä—Å—Ç–≤–æ–≤–∞–Ω–∏—è')\n",
    "print(f'–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π {len(all_results):.0f} —à—Ç—É–∫')\n",
    "print(\n",
    "    f'–ò—Ç–æ–≥–æ–≤—ã–π –ø—Ä–∏—Ä–æ—Å—Ç (–æ—Ç —Ö—É–¥—à–µ–≥–æ) {all_results_useful.end_test_eval.max() * 100 - all_results_useful.end_test_eval.min() * 100:.2f}%')\n",
    "print(f'–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º: 3/10, –æ—á–µ–Ω—å —Ö–æ—Ç–µ–ª 80%+ :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_time</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>end_test_loss</th>\n",
       "      <th>end_test_eval</th>\n",
       "      <th>end_train_loss</th>\n",
       "      <th>end_train_eval</th>\n",
       "      <th>history_test_loss</th>\n",
       "      <th>history_test_eval</th>\n",
       "      <th>history_train_loss</th>\n",
       "      <th>history_train_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_weighted_balance1_ep10_lr2e-5</td>\n",
       "      <td>664.335858</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>2.000000e-05</td>\n",
       "      <td>1.050365</td>\n",
       "      <td>0.689420</td>\n",
       "      <td>0.265091</td>\n",
       "      <td>0.912302</td>\n",
       "      <td>[0.91506, 0.8972, 0.88218, 0.88173, 0.90824, 0...</td>\n",
       "      <td>[0.63914, 0.64417, 0.65828, 0.65102, 0.64439, ...</td>\n",
       "      <td>[1.0441, 0.87621, 0.81221, 0.74153, 0.63697, 0...</td>\n",
       "      <td>[0.52075, 0.62833, 0.66724, 0.69034, 0.73505, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_ep10_lr3e-5_gamma90</td>\n",
       "      <td>789.921810</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>1.046035e-05</td>\n",
       "      <td>0.920411</td>\n",
       "      <td>0.686892</td>\n",
       "      <td>0.351696</td>\n",
       "      <td>0.889575</td>\n",
       "      <td>[0.81054, 0.82058, 0.80676, 0.81373, 0.81999, ...</td>\n",
       "      <td>[0.64583, 0.66161, 0.68164, 0.68683, 0.69438, ...</td>\n",
       "      <td>[0.92772, 0.80844, 0.70641, 0.6447, 0.5949, 0....</td>\n",
       "      <td>[0.60067, 0.66774, 0.72789, 0.76099, 0.78261, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_weighted_balance1_ep10_lr2e-5+ep10...</td>\n",
       "      <td>665.701195</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>8.000000e-06</td>\n",
       "      <td>1.488662</td>\n",
       "      <td>0.671851</td>\n",
       "      <td>0.080462</td>\n",
       "      <td>0.974926</td>\n",
       "      <td>[1.17064, 1.17163, 1.24516, 1.26628, 1.36866, ...</td>\n",
       "      <td>[0.66817, 0.67963, 0.66241, 0.66379, 0.64939, ...</td>\n",
       "      <td>[0.20703, 0.18015, 0.15792, 0.14264, 0.12553, ...</td>\n",
       "      <td>[0.93404, 0.94269, 0.9501, 0.95726, 0.96084, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_balanced_ep10+10_lr3e-5</td>\n",
       "      <td>550.615229</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>3.000000e-05</td>\n",
       "      <td>1.488500</td>\n",
       "      <td>0.670536</td>\n",
       "      <td>0.132767</td>\n",
       "      <td>0.968510</td>\n",
       "      <td>[1.34528, 1.27255, 1.23034, 1.32239, 1.36291, ...</td>\n",
       "      <td>[0.64821, 0.65908, 0.65238, 0.62403, 0.66607, ...</td>\n",
       "      <td>[0.24596, 0.2216, 0.21642, 0.1699, 0.15324, 0....</td>\n",
       "      <td>[0.93366, 0.9407, 0.94118, 0.95988, 0.96403, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_ep15_lr3e-5_gamma75</td>\n",
       "      <td>81.819096</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>4.009038e-07</td>\n",
       "      <td>0.810899</td>\n",
       "      <td>0.666794</td>\n",
       "      <td>0.528303</td>\n",
       "      <td>0.798641</td>\n",
       "      <td>[0.81073, 0.78125, 0.77734, 0.77857, 0.7876, 0...</td>\n",
       "      <td>[0.63781, 0.64985, 0.65889, 0.66724, 0.66609, ...</td>\n",
       "      <td>[0.92728, 0.7626, 0.70039, 0.65345, 0.62534, 0...</td>\n",
       "      <td>[0.56902, 0.67421, 0.70677, 0.72994, 0.74978, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_freeze_cls_top6_noemb_ep10_lr2e-5</td>\n",
       "      <td>567.160578</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>2.000000e-05</td>\n",
       "      <td>0.949296</td>\n",
       "      <td>0.663690</td>\n",
       "      <td>0.521717</td>\n",
       "      <td>0.817811</td>\n",
       "      <td>[0.93321, 0.92425, 0.90861, 0.89061, 0.89768, ...</td>\n",
       "      <td>[0.61329, 0.62359, 0.64036, 0.63553, 0.63863, ...</td>\n",
       "      <td>[1.03076, 0.89112, 0.83194, 0.77583, 0.72885, ...</td>\n",
       "      <td>[0.56114, 0.62451, 0.66551, 0.69195, 0.7143, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_ep15_lr3e-5_gamma50</td>\n",
       "      <td>80.672499</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>9.155273e-10</td>\n",
       "      <td>0.778388</td>\n",
       "      <td>0.659627</td>\n",
       "      <td>0.676965</td>\n",
       "      <td>0.719121</td>\n",
       "      <td>[0.81073, 0.78908, 0.78093, 0.7806, 0.78153, 0...</td>\n",
       "      <td>[0.63781, 0.64628, 0.64886, 0.65259, 0.65431, ...</td>\n",
       "      <td>[0.92728, 0.76537, 0.72155, 0.69749, 0.69167, ...</td>\n",
       "      <td>[0.56902, 0.67488, 0.69669, 0.70413, 0.71104, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_freeze_cls_top6_noemb_ep10_lr2e-5+...</td>\n",
       "      <td>573.790415</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>1.104489</td>\n",
       "      <td>0.657930</td>\n",
       "      <td>0.312919</td>\n",
       "      <td>0.896986</td>\n",
       "      <td>[0.97514, 1.00167, 1.02289, 1.0422, 1.07174, 1...</td>\n",
       "      <td>[0.66743, 0.66916, 0.6611, 0.66455, 0.64987, 0...</td>\n",
       "      <td>[0.47712, 0.45034, 0.42656, 0.40578, 0.38779, ...</td>\n",
       "      <td>[0.83523, 0.84783, 0.85413, 0.86191, 0.86981, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_ep4_lr2e-5</td>\n",
       "      <td>313.314843</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>2.000000e-05</td>\n",
       "      <td>0.845497</td>\n",
       "      <td>0.653482</td>\n",
       "      <td>0.829568</td>\n",
       "      <td>0.642292</td>\n",
       "      <td>[0.87523, 0.89607, 1.07348, 0.8455]</td>\n",
       "      <td>[0.6146, 0.61236, 0.44899, 0.65348]</td>\n",
       "      <td>[1.00294, 0.89225, 0.87825, 0.82957]</td>\n",
       "      <td>[0.54867, 0.61623, 0.62414, 0.64229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_freeze_enc_cls_ep15_lr1e-5</td>\n",
       "      <td>146.357875</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.810099</td>\n",
       "      <td>0.652300</td>\n",
       "      <td>0.514675</td>\n",
       "      <td>0.798765</td>\n",
       "      <td>[1.01663, 0.98507, 0.96149, 0.93789, 0.91417, ...</td>\n",
       "      <td>[0.50908, 0.52555, 0.53718, 0.55409, 0.5697, 0...</td>\n",
       "      <td>[1.04851, 0.99458, 0.96636, 0.93974, 0.91298, ...</td>\n",
       "      <td>[0.49397, 0.51875, 0.5418, 0.55539, 0.57248, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_balanced_ep4_lr4e-5</td>\n",
       "      <td>216.815594</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>4.000000e-05</td>\n",
       "      <td>0.920076</td>\n",
       "      <td>0.648289</td>\n",
       "      <td>0.660652</td>\n",
       "      <td>0.751375</td>\n",
       "      <td>[0.90084, 0.83361, 0.87564, 0.92008]</td>\n",
       "      <td>[0.62433, 0.64315, 0.64717, 0.64829]</td>\n",
       "      <td>[0.99145, 0.84269, 0.77391, 0.66065]</td>\n",
       "      <td>[0.54661, 0.64511, 0.68667, 0.75137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_ep15_lr3e-5</td>\n",
       "      <td>84.419073</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>3.000000e-05</td>\n",
       "      <td>1.498644</td>\n",
       "      <td>0.648159</td>\n",
       "      <td>0.122758</td>\n",
       "      <td>0.959536</td>\n",
       "      <td>[0.81073, 0.77603, 0.7722, 0.78766, 0.82281, 0...</td>\n",
       "      <td>[0.63781, 0.65775, 0.66922, 0.6718, 0.67094, 0...</td>\n",
       "      <td>[0.92728, 0.76131, 0.68418, 0.61027, 0.54613, ...</td>\n",
       "      <td>[0.56902, 0.67354, 0.71821, 0.75472, 0.79079, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_ep15_lr3e-6</td>\n",
       "      <td>80.687391</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>3.000000e-06</td>\n",
       "      <td>0.787649</td>\n",
       "      <td>0.645993</td>\n",
       "      <td>0.719137</td>\n",
       "      <td>0.695405</td>\n",
       "      <td>[1.02799, 0.99297, 0.96351, 0.92789, 0.89032, ...</td>\n",
       "      <td>[0.50707, 0.52039, 0.53832, 0.55995, 0.59566, ...</td>\n",
       "      <td>[1.06019, 1.00558, 0.97351, 0.93928, 0.90197, ...</td>\n",
       "      <td>[0.48434, 0.51294, 0.54049, 0.5626, 0.58841, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_freeze_cls_top6_ep10_lr1e-5</td>\n",
       "      <td>405.729003</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.886515</td>\n",
       "      <td>0.629704</td>\n",
       "      <td>0.911074</td>\n",
       "      <td>0.605237</td>\n",
       "      <td>[0.95064, 0.94153, 0.93114, 0.92057, 0.91644, ...</td>\n",
       "      <td>[0.60781, 0.61386, 0.61905, 0.62308, 0.61905, ...</td>\n",
       "      <td>[1.11139, 0.9408, 0.93733, 0.92899, 0.92296, 0...</td>\n",
       "      <td>[0.52087, 0.59647, 0.59536, 0.60067, 0.59918, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_freeze_cls_top6_ep10_lr1e-5+ep5_lr...</td>\n",
       "      <td>196.886868</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>3.000000e-05</td>\n",
       "      <td>0.891213</td>\n",
       "      <td>0.625896</td>\n",
       "      <td>0.893934</td>\n",
       "      <td>0.610178</td>\n",
       "      <td>[0.91383, 0.90004, 0.90342, 0.9, 0.89121]</td>\n",
       "      <td>[0.6305, 0.62791, 0.61921, 0.63188, 0.6259]</td>\n",
       "      <td>[0.90481, 0.90538, 0.90045, 0.89832, 0.89393]</td>\n",
       "      <td>[0.6103, 0.60697, 0.61487, 0.61265, 0.61018]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_freeze_emb_cls_ep15_lr8e-4_gamma75</td>\n",
       "      <td>141.551475</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>1.428657e-07</td>\n",
       "      <td>1.747256</td>\n",
       "      <td>0.614743</td>\n",
       "      <td>0.046346</td>\n",
       "      <td>0.987451</td>\n",
       "      <td>[0.78195, 0.86675, 1.06366, 1.19915, 1.33561, ...</td>\n",
       "      <td>[0.64988, 0.65201, 0.64227, 0.63022, 0.60987, ...</td>\n",
       "      <td>[0.88908, 0.57243, 0.35045, 0.22411, 0.16062, ...</td>\n",
       "      <td>[0.59474, 0.77038, 0.87379, 0.92759, 0.95168, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_tiny_freeze_cls_ep15_lr3e-3_gamma75</td>\n",
       "      <td>84.873471</td>\n",
       "      <td>NoneType</td>\n",
       "      <td>5.357463e-07</td>\n",
       "      <td>0.857673</td>\n",
       "      <td>0.607288</td>\n",
       "      <td>0.864347</td>\n",
       "      <td>0.602841</td>\n",
       "      <td>[0.92251, 0.89501, 0.88302, 0.87648, 0.87191, ...</td>\n",
       "      <td>[0.55654, 0.57518, 0.58477, 0.5862, 0.59021, 0...</td>\n",
       "      <td>[0.95345, 0.90167, 0.88746, 0.87755, 0.87572, ...</td>\n",
       "      <td>[0.54158, 0.58681, 0.58649, 0.58977, 0.59125, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rubert_base_freeze_cls_ep10_lr1e-5</td>\n",
       "      <td>226.633366</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.946604</td>\n",
       "      <td>0.605447</td>\n",
       "      <td>0.949604</td>\n",
       "      <td>0.598691</td>\n",
       "      <td>[1.19549, 0.97856, 0.94208, 0.93703, 0.94097, ...</td>\n",
       "      <td>[0.4232, 0.58045, 0.59767, 0.60717, 0.60573, 0...</td>\n",
       "      <td>[1.64798, 1.15789, 1.03554, 0.98945, 0.97381, ...</td>\n",
       "      <td>[0.27458, 0.51161, 0.57868, 0.59881, 0.59523, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  train_time  \\\n",
       "0          rubert_base_weighted_balance1_ep10_lr2e-5  664.335858   \n",
       "0                    rubert_base_ep10_lr3e-5_gamma90  789.921810   \n",
       "0  rubert_base_weighted_balance1_ep10_lr2e-5+ep10...  665.701195   \n",
       "0                rubert_base_balanced_ep10+10_lr3e-5  550.615229   \n",
       "0                    rubert_tiny_ep15_lr3e-5_gamma75   81.819096   \n",
       "0      rubert_base_freeze_cls_top6_noemb_ep10_lr2e-5  567.160578   \n",
       "0                    rubert_tiny_ep15_lr3e-5_gamma50   80.672499   \n",
       "0  rubert_base_freeze_cls_top6_noemb_ep10_lr2e-5+...  573.790415   \n",
       "0                             rubert_base_ep4_lr2e-5  313.314843   \n",
       "0             rubert_tiny_freeze_enc_cls_ep15_lr1e-5  146.357875   \n",
       "0                    rubert_base_balanced_ep4_lr4e-5  216.815594   \n",
       "0                            rubert_tiny_ep15_lr3e-5   84.419073   \n",
       "0                            rubert_tiny_ep15_lr3e-6   80.687391   \n",
       "0            rubert_base_freeze_cls_top6_ep10_lr1e-5  405.729003   \n",
       "0  rubert_base_freeze_cls_top6_ep10_lr1e-5+ep5_lr...  196.886868   \n",
       "0     rubert_tiny_freeze_emb_cls_ep15_lr8e-4_gamma75  141.551475   \n",
       "0         rubert_tiny_freeze_cls_ep15_lr3e-3_gamma75   84.873471   \n",
       "0                 rubert_base_freeze_cls_ep10_lr1e-5  226.633366   \n",
       "\n",
       "      loss_function  learning_rate  end_test_loss  end_test_eval  \\\n",
       "0  CrossEntropyLoss   2.000000e-05       1.050365       0.689420   \n",
       "0          NoneType   1.046035e-05       0.920411       0.686892   \n",
       "0  CrossEntropyLoss   8.000000e-06       1.488662       0.671851   \n",
       "0          NoneType   3.000000e-05       1.488500       0.670536   \n",
       "0          NoneType   4.009038e-07       0.810899       0.666794   \n",
       "0  CrossEntropyLoss   2.000000e-05       0.949296       0.663690   \n",
       "0          NoneType   9.155273e-10       0.778388       0.659627   \n",
       "0  CrossEntropyLoss   1.000000e-05       1.104489       0.657930   \n",
       "0          NoneType   2.000000e-05       0.845497       0.653482   \n",
       "0          NoneType   1.000000e-05       0.810099       0.652300   \n",
       "0          NoneType   4.000000e-05       0.920076       0.648289   \n",
       "0          NoneType   3.000000e-05       1.498644       0.648159   \n",
       "0          NoneType   3.000000e-06       0.787649       0.645993   \n",
       "0  CrossEntropyLoss   1.000000e-05       0.886515       0.629704   \n",
       "0  CrossEntropyLoss   3.000000e-05       0.891213       0.625896   \n",
       "0          NoneType   1.428657e-07       1.747256       0.614743   \n",
       "0          NoneType   5.357463e-07       0.857673       0.607288   \n",
       "0  CrossEntropyLoss   1.000000e-05       0.946604       0.605447   \n",
       "\n",
       "   end_train_loss  end_train_eval  \\\n",
       "0        0.265091        0.912302   \n",
       "0        0.351696        0.889575   \n",
       "0        0.080462        0.974926   \n",
       "0        0.132767        0.968510   \n",
       "0        0.528303        0.798641   \n",
       "0        0.521717        0.817811   \n",
       "0        0.676965        0.719121   \n",
       "0        0.312919        0.896986   \n",
       "0        0.829568        0.642292   \n",
       "0        0.514675        0.798765   \n",
       "0        0.660652        0.751375   \n",
       "0        0.122758        0.959536   \n",
       "0        0.719137        0.695405   \n",
       "0        0.911074        0.605237   \n",
       "0        0.893934        0.610178   \n",
       "0        0.046346        0.987451   \n",
       "0        0.864347        0.602841   \n",
       "0        0.949604        0.598691   \n",
       "\n",
       "                                   history_test_loss  \\\n",
       "0  [0.91506, 0.8972, 0.88218, 0.88173, 0.90824, 0...   \n",
       "0  [0.81054, 0.82058, 0.80676, 0.81373, 0.81999, ...   \n",
       "0  [1.17064, 1.17163, 1.24516, 1.26628, 1.36866, ...   \n",
       "0  [1.34528, 1.27255, 1.23034, 1.32239, 1.36291, ...   \n",
       "0  [0.81073, 0.78125, 0.77734, 0.77857, 0.7876, 0...   \n",
       "0  [0.93321, 0.92425, 0.90861, 0.89061, 0.89768, ...   \n",
       "0  [0.81073, 0.78908, 0.78093, 0.7806, 0.78153, 0...   \n",
       "0  [0.97514, 1.00167, 1.02289, 1.0422, 1.07174, 1...   \n",
       "0                [0.87523, 0.89607, 1.07348, 0.8455]   \n",
       "0  [1.01663, 0.98507, 0.96149, 0.93789, 0.91417, ...   \n",
       "0               [0.90084, 0.83361, 0.87564, 0.92008]   \n",
       "0  [0.81073, 0.77603, 0.7722, 0.78766, 0.82281, 0...   \n",
       "0  [1.02799, 0.99297, 0.96351, 0.92789, 0.89032, ...   \n",
       "0  [0.95064, 0.94153, 0.93114, 0.92057, 0.91644, ...   \n",
       "0          [0.91383, 0.90004, 0.90342, 0.9, 0.89121]   \n",
       "0  [0.78195, 0.86675, 1.06366, 1.19915, 1.33561, ...   \n",
       "0  [0.92251, 0.89501, 0.88302, 0.87648, 0.87191, ...   \n",
       "0  [1.19549, 0.97856, 0.94208, 0.93703, 0.94097, ...   \n",
       "\n",
       "                                   history_test_eval  \\\n",
       "0  [0.63914, 0.64417, 0.65828, 0.65102, 0.64439, ...   \n",
       "0  [0.64583, 0.66161, 0.68164, 0.68683, 0.69438, ...   \n",
       "0  [0.66817, 0.67963, 0.66241, 0.66379, 0.64939, ...   \n",
       "0  [0.64821, 0.65908, 0.65238, 0.62403, 0.66607, ...   \n",
       "0  [0.63781, 0.64985, 0.65889, 0.66724, 0.66609, ...   \n",
       "0  [0.61329, 0.62359, 0.64036, 0.63553, 0.63863, ...   \n",
       "0  [0.63781, 0.64628, 0.64886, 0.65259, 0.65431, ...   \n",
       "0  [0.66743, 0.66916, 0.6611, 0.66455, 0.64987, 0...   \n",
       "0                [0.6146, 0.61236, 0.44899, 0.65348]   \n",
       "0  [0.50908, 0.52555, 0.53718, 0.55409, 0.5697, 0...   \n",
       "0               [0.62433, 0.64315, 0.64717, 0.64829]   \n",
       "0  [0.63781, 0.65775, 0.66922, 0.6718, 0.67094, 0...   \n",
       "0  [0.50707, 0.52039, 0.53832, 0.55995, 0.59566, ...   \n",
       "0  [0.60781, 0.61386, 0.61905, 0.62308, 0.61905, ...   \n",
       "0        [0.6305, 0.62791, 0.61921, 0.63188, 0.6259]   \n",
       "0  [0.64988, 0.65201, 0.64227, 0.63022, 0.60987, ...   \n",
       "0  [0.55654, 0.57518, 0.58477, 0.5862, 0.59021, 0...   \n",
       "0  [0.4232, 0.58045, 0.59767, 0.60717, 0.60573, 0...   \n",
       "\n",
       "                                  history_train_loss  \\\n",
       "0  [1.0441, 0.87621, 0.81221, 0.74153, 0.63697, 0...   \n",
       "0  [0.92772, 0.80844, 0.70641, 0.6447, 0.5949, 0....   \n",
       "0  [0.20703, 0.18015, 0.15792, 0.14264, 0.12553, ...   \n",
       "0  [0.24596, 0.2216, 0.21642, 0.1699, 0.15324, 0....   \n",
       "0  [0.92728, 0.7626, 0.70039, 0.65345, 0.62534, 0...   \n",
       "0  [1.03076, 0.89112, 0.83194, 0.77583, 0.72885, ...   \n",
       "0  [0.92728, 0.76537, 0.72155, 0.69749, 0.69167, ...   \n",
       "0  [0.47712, 0.45034, 0.42656, 0.40578, 0.38779, ...   \n",
       "0               [1.00294, 0.89225, 0.87825, 0.82957]   \n",
       "0  [1.04851, 0.99458, 0.96636, 0.93974, 0.91298, ...   \n",
       "0               [0.99145, 0.84269, 0.77391, 0.66065]   \n",
       "0  [0.92728, 0.76131, 0.68418, 0.61027, 0.54613, ...   \n",
       "0  [1.06019, 1.00558, 0.97351, 0.93928, 0.90197, ...   \n",
       "0  [1.11139, 0.9408, 0.93733, 0.92899, 0.92296, 0...   \n",
       "0      [0.90481, 0.90538, 0.90045, 0.89832, 0.89393]   \n",
       "0  [0.88908, 0.57243, 0.35045, 0.22411, 0.16062, ...   \n",
       "0  [0.95345, 0.90167, 0.88746, 0.87755, 0.87572, ...   \n",
       "0  [1.64798, 1.15789, 1.03554, 0.98945, 0.97381, ...   \n",
       "\n",
       "                                  history_train_eval  \n",
       "0  [0.52075, 0.62833, 0.66724, 0.69034, 0.73505, ...  \n",
       "0  [0.60067, 0.66774, 0.72789, 0.76099, 0.78261, ...  \n",
       "0  [0.93404, 0.94269, 0.9501, 0.95726, 0.96084, 0...  \n",
       "0  [0.93366, 0.9407, 0.94118, 0.95988, 0.96403, 0...  \n",
       "0  [0.56902, 0.67421, 0.70677, 0.72994, 0.74978, ...  \n",
       "0  [0.56114, 0.62451, 0.66551, 0.69195, 0.7143, 0...  \n",
       "0  [0.56902, 0.67488, 0.69669, 0.70413, 0.71104, ...  \n",
       "0  [0.83523, 0.84783, 0.85413, 0.86191, 0.86981, ...  \n",
       "0               [0.54867, 0.61623, 0.62414, 0.64229]  \n",
       "0  [0.49397, 0.51875, 0.5418, 0.55539, 0.57248, 0...  \n",
       "0               [0.54661, 0.64511, 0.68667, 0.75137]  \n",
       "0  [0.56902, 0.67354, 0.71821, 0.75472, 0.79079, ...  \n",
       "0  [0.48434, 0.51294, 0.54049, 0.5626, 0.58841, 0...  \n",
       "0  [0.52087, 0.59647, 0.59536, 0.60067, 0.59918, ...  \n",
       "0       [0.6103, 0.60697, 0.61487, 0.61265, 0.61018]  \n",
       "0  [0.59474, 0.77038, 0.87379, 0.92759, 0.95168, ...  \n",
       "0  [0.54158, 0.58681, 0.58649, 0.58977, 0.59125, ...  \n",
       "0  [0.27458, 0.51161, 0.57868, 0.59881, 0.59523, ...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_useful.sort_values(by='end_test_eval', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ï—â–µ –º–æ–∂–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å, —á—Ç–æ –µ—Å–ª–∏ –¥—ë—Ä–≥–∞—Ç—å —Ä–∞–Ω–Ω–∏–π –æ—Å—Ç–∞–Ω–æ–≤, —Ç–æ –≥–¥–µ-—Ç–æ —Ç–∞–º –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã 71% –Ω–∞ —Ç–µ—Å—Ç–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(text, model, tokenize):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        text = clean_text(text)\n",
    "        tokenized = tokenize(text)\n",
    "        tokenized[0] = tokenized[0].to(device)\n",
    "        tokenized[1] = tokenized[1].to(device)\n",
    "        evaluated = model(tokenized[0], token_type_ids=None, attention_mask=tokenized[1])\n",
    "        print(class_names[torch.argmax(evaluated.logits, dim=-1).detach().cpu().numpy()[0]], text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "–ù–∞—Ç—è–Ω–µ–º –ª—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ (–∏—Ö –Ω—É–∂–Ω–æ –∑–∞–Ω–æ–≤–æ –ø—Ä–æ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å, —Ç–∫ —è –∏—Ö —á–∏—â—É)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"---NEGATIVE---\",\n",
    "    # negative\n",
    "    \"–∞—Ö —Ç—ã —Å—É–∫–∞ —Ç–∞–∫–∞—è\",\n",
    "    \"—á—Ç–æ–± —Ç—ã —Å–¥–æ—Ö\",\n",
    "    \"–≥–Ω–∏–¥–æ–π –±—ã–ª –∏ –≥–Ω–∏–¥–æ–π –æ—Å—Ç–∞–ª—Å—è\",\n",
    "    \"–Ω–µ –±—Ä–∞—Ç —Ç—ã –º–Ω–µ, –≥–Ω–∏–¥–∞ —á–µ—Ä–Ω–æ–∂–æ–ø–∞—è\",\n",
    "    \"---NEUTRAL---\",\n",
    "    # neutral\n",
    "    \"—Å—É–∫–∞ - —ç—Ç–æ —Å–æ–±–∞–∫–∞ –∂–µ–Ω—Å–∫–æ–≥–æ –ø–æ–ª–∞\",\n",
    "    \"–º–∞—Ç—ã –≤ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –æ—á–µ–Ω—å –¥–∞–≤–Ω–æ –Ω–∞–ø—Ä–∏–º–µ—Ä —Å–ª–æ–≤–æ '—Ö—É–π'\",\n",
    "    \"–Ω–µ–≥—Ä—ã - —ç—Ç–æ –ª—é–¥–∏ —Å —á–µ—Ä–Ω–æ–π –∫–æ–∂–µ–π, —Ç–∞–∫–∏–µ –∂–µ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∫ –∏ –º—ã —Å –≤–∞–º–∏\",\n",
    "    \"–ø—É—Ç–∏–Ω\",\n",
    "    \"---POSITIVE---\",\n",
    "    # positive\n",
    "    \"—Å–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å\",\n",
    "    \"–ª—é–±–ª—é —Ç–µ–±—è\",\n",
    "    \"—Ç—ã –º–æ–π –ª—É—á—à–∏–π –¥—Ä—É–≥\",\n",
    "    \"—Ç—ã –º–æ–π –±—Ä–∞—Ç, –∏ —è —Ü–µ–Ω—é —ç—Ç–æ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral ---negative---\n",
      "negative –∞—Ö —Ç—ã —Å—É–∫–∞ —Ç–∞–∫–∞—è\n",
      "negative —á—Ç–æ–± —Ç—ã —Å–¥–æ—Ö\n",
      "negative –≥–Ω–∏–¥–æ–π –±—ã–ª –∏ –≥–Ω–∏–¥–æ–π –æ—Å—Ç–∞–ª—Å—è\n",
      "negative –Ω–µ –±—Ä–∞—Ç —Ç—ã –º–Ω–µ, –≥–Ω–∏–¥–∞ —á–µ—Ä–Ω–æ–∂–æ–ø–∞—è\n",
      "neutral ---neutral---\n",
      "negative —Å—É–∫–∞ - —ç—Ç–æ —Å–æ–±–∞–∫–∞ –∂–µ–Ω—Å–∫–æ–≥–æ –ø–æ–ª–∞\n",
      "negative –º–∞—Ç—ã –≤ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –æ—á–µ–Ω—å –¥–∞–≤–Ω–æ –Ω–∞–ø—Ä–∏–º–µ—Ä —Å–ª–æ–≤–æ '—Ö—É–π'\n",
      "neutral –Ω–µ–≥—Ä—ã - —ç—Ç–æ –ª—é–¥–∏ —Å —á–µ—Ä–Ω–æ–π –∫–æ–∂–µ–π, —Ç–∞–∫–∏–µ –∂–µ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∫ –∏ –º—ã —Å –≤–∞–º–∏\n",
      "neutral –ø—É—Ç–∏–Ω\n",
      "negative ---positive---\n",
      "neutral —Å–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å\n",
      "positive –ª—é–±–ª—é —Ç–µ–±—è\n",
      "positive —Ç—ã –º–æ–π –ª—É—á—à–∏–π –¥—Ä—É–≥\n",
      "positive —Ç—ã –º–æ–π –±—Ä–∞—Ç, –∏ —è —Ü–µ–Ω—é —ç—Ç–æ\n"
     ]
    }
   ],
   "source": [
    "for example in examples:\n",
    "    predict(example, rubert_base_weighted_balance1, tokenize_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral ---negative---\n",
      "negative –∞—Ö —Ç—ã —Å—É–∫–∞ —Ç–∞–∫–∞—è\n",
      "negative —á—Ç–æ–± —Ç—ã —Å–¥–æ—Ö\n",
      "negative –≥–Ω–∏–¥–æ–π –±—ã–ª –∏ –≥–Ω–∏–¥–æ–π –æ—Å—Ç–∞–ª—Å—è\n",
      "negative –Ω–µ –±—Ä–∞—Ç —Ç—ã –º–Ω–µ, –≥–Ω–∏–¥–∞ —á–µ—Ä–Ω–æ–∂–æ–ø–∞—è\n",
      "neutral ---neutral---\n",
      "negative —Å—É–∫–∞ - —ç—Ç–æ —Å–æ–±–∞–∫–∞ –∂–µ–Ω—Å–∫–æ–≥–æ –ø–æ–ª–∞\n",
      "negative –º–∞—Ç—ã –≤ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –æ—á–µ–Ω—å –¥–∞–≤–Ω–æ –Ω–∞–ø—Ä–∏–º–µ—Ä —Å–ª–æ–≤–æ '—Ö—É–π'\n",
      "neutral –Ω–µ–≥—Ä—ã - —ç—Ç–æ –ª—é–¥–∏ —Å —á–µ—Ä–Ω–æ–π –∫–æ–∂–µ–π, —Ç–∞–∫–∏–µ –∂–µ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∫ –∏ –º—ã —Å –≤–∞–º–∏\n",
      "negative –ø—É—Ç–∏–Ω\n",
      "negative ---positive---\n",
      "neutral —Å–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å\n",
      "positive –ª—é–±–ª—é —Ç–µ–±—è\n",
      "positive —Ç—ã –º–æ–π –ª—É—á—à–∏–π –¥—Ä—É–≥\n",
      "positive —Ç—ã –º–æ–π –±—Ä–∞—Ç, –∏ —è —Ü–µ–Ω—é —ç—Ç–æ\n"
     ]
    }
   ],
   "source": [
    "for example in examples:\n",
    "    predict(example, rubert_base2, tokenize_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral ---negative---\n",
      "negative –∞—Ö —Ç—ã —Å—É–∫–∞ —Ç–∞–∫–∞—è\n",
      "negative —á—Ç–æ–± —Ç—ã —Å–¥–æ—Ö\n",
      "neutral –≥–Ω–∏–¥–æ–π –±—ã–ª –∏ –≥–Ω–∏–¥–æ–π –æ—Å—Ç–∞–ª—Å—è\n",
      "negative –Ω–µ –±—Ä–∞—Ç —Ç—ã –º–Ω–µ, –≥–Ω–∏–¥–∞ —á–µ—Ä–Ω–æ–∂–æ–ø–∞—è\n",
      "neutral ---neutral---\n",
      "neutral —Å—É–∫–∞ - —ç—Ç–æ —Å–æ–±–∞–∫–∞ –∂–µ–Ω—Å–∫–æ–≥–æ –ø–æ–ª–∞\n",
      "neutral –º–∞—Ç—ã –≤ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –æ—á–µ–Ω—å –¥–∞–≤–Ω–æ –Ω–∞–ø—Ä–∏–º–µ—Ä —Å–ª–æ–≤–æ '—Ö—É–π'\n",
      "negative –Ω–µ–≥—Ä—ã - —ç—Ç–æ –ª—é–¥–∏ —Å —á–µ—Ä–Ω–æ–π –∫–æ–∂–µ–π, —Ç–∞–∫–∏–µ –∂–µ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∫ –∏ –º—ã —Å –≤–∞–º–∏\n",
      "neutral –ø—É—Ç–∏–Ω\n",
      "neutral ---positive---\n",
      "neutral —Å–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å\n",
      "positive –ª—é–±–ª—é —Ç–µ–±—è\n",
      "positive —Ç—ã –º–æ–π –ª—É—á—à–∏–π –¥—Ä—É–≥\n",
      "neutral —Ç—ã –º–æ–π –±—Ä–∞—Ç, –∏ —è —Ü–µ–Ω—é —ç—Ç–æ\n"
     ]
    }
   ],
   "source": [
    "for example in examples:\n",
    "    predict(example, rubert_tiny4, tokenize_tiny)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
